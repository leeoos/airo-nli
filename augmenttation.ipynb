{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "import torch\n",
    "from datasets import load_dataset, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/leeoos/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'premise', 'hypothesis', 'label', 'wsd', 'srl'],\n",
       "        num_rows: 51086\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'premise', 'hypothesis', 'label', 'wsd', 'srl'],\n",
       "        num_rows: 2288\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'premise', 'hypothesis', 'label', 'wsd', 'srl'],\n",
       "        num_rows: 2287\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load chunk of FEVER datyaset\n",
    "fever_dataset = load_dataset(\"tommasobonomo/sem_augmented_fever_nli\", trust_remote_code=True)\n",
    "\n",
    "# structure of the dataset\n",
    "fever_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 51086/51086 [00:00<00:00, 174251.73 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 2288/2288 [00:00<00:00, 111925.07 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 2287/2287 [00:00<00:00, 106856.19 examples/s]\n"
     ]
    }
   ],
   "source": [
    "fever_dataset.save_to_disk(\"./dataset/fever_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_fever_dataset = load_from_disk(\"./dataset/fever_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'premise', 'hypothesis', 'label', 'wsd', 'srl'],\n",
       "        num_rows: 51086\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'premise', 'hypothesis', 'label', 'wsd', 'srl'],\n",
       "        num_rows: 2288\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'premise', 'hypothesis', 'label', 'wsd', 'srl'],\n",
       "        num_rows: 2287\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_fever_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['premise', 'hypothesis'])\n"
     ]
    }
   ],
   "source": [
    "print(fever_dataset['train'][0]['srl'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'index': 0, 'rawText': 'Roman'}, {'index': 1, 'rawText': 'Atwood'}, {'index': 2, 'rawText': 'is'}, {'index': 3, 'rawText': 'a'}, {'index': 4, 'rawText': 'content'}, {'index': 5, 'rawText': 'creator'}, {'index': 6, 'rawText': '.'}]\n",
      "[{'tokenIndex': 2, 'verbatlas': {'frameName': 'COPULA', 'roles': [{'role': 'Theme', 'score': 1.0, 'span': [0, 2]}, {'role': 'Attribute', 'score': 1.0, 'span': [3, 6]}]}, 'englishPropbank': {'frameName': 'be.01', 'roles': [{'role': 'ARG1', 'score': 1.0, 'span': [0, 2]}, {'role': 'ARG2', 'score': 1.0, 'span': [3, 6]}]}}]\n"
     ]
    }
   ],
   "source": [
    "print(fever_dataset['train'][0]['srl']['hypothesis']['tokens'])\n",
    "print(fever_dataset['train'][0]['srl']['hypothesis']['annotations'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "The following prompt can be used to correct the grammare of a modified hypotesis so if just a not is added the phrase is transformed in negative form\n",
    "Correct the grammar in the following inputs, rephrase the input if necessary to make them more accurate. Provide just the correct version, no explanation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataset = fever_dataset.filter(lambda examples: examples['label'] != 'NOT ENOUGH INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 1.34k/1.34k [00:00<00:00, 1.53MB/s]\n",
      "Downloading data: 100%|██████████| 73.1k/73.1k [00:00<00:00, 137kB/s]\n",
      "Generating test split: 100%|██████████| 337/337 [00:00<00:00, 34000.78 examples/s]\n"
     ]
    }
   ],
   "source": [
    "adversarial_testset = load_dataset(\"iperbole/adversarial_fever_nli\", trust_remote_code=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
