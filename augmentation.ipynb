{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download configuratiins\n",
    "download_from_remote = True\n",
    "load_from_local = True\n",
    "save_to_local = True\n",
    "local_dataset = \"./dataset/fever_dataset\"\n",
    "local_adversarial = \"./dataset/adversarial_dataset\"\n",
    "%mkdir -p {local_dataset}\n",
    "%mkdir -p {local_adversarial}\n",
    "\n",
    "# data analytics\n",
    "test_tokenizer = False\n",
    "print_statistics = False\n",
    "\n",
    "# dataset exploration\n",
    "general_structure = True\n",
    "show_ids = False\n",
    "show_labels = False\n",
    "wsd_exploration = False\n",
    "srl_exploration = True\n",
    "\n",
    "# semantic roles\n",
    "save_info = False\n",
    "info = \"./info/\"\n",
    "%mkdir -p {info}\n",
    "\n",
    "\n",
    "# augmentation\n",
    "syn_hyp_augment = True\n",
    "save_graph = False\n",
    "load_graph = True\n",
    "graph = \"./relational_graph\"\n",
    "%mkdir -p {graph}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leeoos/miniconda3/envs/nlp/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package wordnet to /home/leeoos/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/leeoos/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# general imports\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import string\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# visualization and statistics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "from datasets import(\n",
    "  Dataset, \n",
    "  load_dataset, \n",
    "  load_from_disk, \n",
    "  concatenate_datasets,\n",
    ") \n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('wordnet')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# spacy\n",
    "import spacy \n",
    "# Load the SpaCy model\n",
    "nlp_spacy = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# huggingface\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "# set seeds\n",
    "set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data from local repository\n",
      "Done!\n",
      "Train ssplit length: 51086\n",
      "Max id in train split: 99998\n"
     ]
    }
   ],
   "source": [
    "#@title Download data or just load from local \n",
    "\n",
    "download_from_remote = not(os.path.exists(local_dataset) and os.path.exists(local_adversarial))\n",
    "\n",
    "if download_from_remote:\n",
    "    print(\"Downloading data from remote repository\")\n",
    "\n",
    "    # load chunk of FEVER datyaset\n",
    "    fever_dataset = load_dataset(\"tommasobonomo/sem_augmented_fever_nli\", trust_remote_code=True)\n",
    "\n",
    "    # load adversarial \n",
    "    adversarial_testset = load_dataset(\"iperbole/adversarial_fever_nli\", trust_remote_code=True)\n",
    "\n",
    "    # structure of the dataset\n",
    "    print(fever_dataset)\n",
    "\n",
    "    if save_to_local:\n",
    "        print(f\"Save data in local {local_dataset}\")\n",
    "        fever_dataset.save_to_disk(local_dataset)\n",
    "        print(f\"Save adversarial dataset in {local_adversarial}\")\n",
    "        adversarial_testset.save_to_disk(local_adversarial)\n",
    "\n",
    "elif load_from_local:\n",
    "    print(f\"Load data from local repository\")\n",
    "    fever_dataset = load_from_disk(local_dataset)\n",
    "    adversarial_testset = load_from_disk(local_adversarial)\n",
    "    \n",
    "print(\"Done!\")\n",
    "\n",
    "print(f\"Train ssplit length: {len(fever_dataset['train'])}\")\n",
    "max_id = max(fever_dataset['train']['id'])\n",
    "print(f\"Max id in train split: {max_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Tokenization function for datapoint visualization\n",
    "\n",
    "if test_tokenizer:\n",
    "        \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    label_map = {\n",
    "        'ENTAILMENT': 0,\n",
    "        'NEUTRAL': 1,\n",
    "        'CONTRADICTION': 2,\n",
    "        'NOT ENOUGH INFO': None\n",
    "    }\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        examples['label'] = [label_map[label] for label in examples['label']]\n",
    "        return tokenizer(examples['premise'], examples['hypothesis'], padding=True, truncation=True)\n",
    "\n",
    "\n",
    "    # tokenized = fever_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Exploration utils\n",
    "\n",
    "def pretty_print_dict(d, indent=0):\n",
    "    for key, value in d.items():\n",
    "        print(' ' * indent + str(key) + ':', end=' ')\n",
    "        if isinstance(value, dict):\n",
    "            print()\n",
    "            pretty_print_dict(value, indent + 4)\n",
    "        else:\n",
    "            print(value)\n",
    "\n",
    "\n",
    "def plot_labels_distribution(target_set, title=''):\n",
    "\n",
    "    labels = [\n",
    "        'ENTAILMENT',\n",
    "        'NEUTRAL',\n",
    "        'CONTRADICTION',\n",
    "    ]\n",
    "\n",
    "    label_counts = {}\n",
    "    for label in target_set['label']:\n",
    "        if label not in label_counts:\n",
    "            label_counts[label] = 0\n",
    "        label_counts[label] += 1\n",
    "\n",
    "    plt.bar(labels, label_counts.values())\n",
    "    plt.xlabel('Label')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(f'Distribution of labels in {title}')\n",
    "    plt.show()\n",
    "    print()\n",
    "        \n",
    "\n",
    "def plot_lengths_distribution(target_set, title='', compare_length=False):\n",
    "    # extract premises and hypotheses\n",
    "    premises = [item['premise'] for item in target_set]\n",
    "    hypotheses = [item['hypothesis'] for item in target_set]\n",
    "\n",
    "    # compute lengths\n",
    "    premise_lengths = [len(premise.split()) for premise in premises]\n",
    "    hypothesis_lengths = [len(hypothesis.split()) for hypothesis in hypotheses]\n",
    "\n",
    "    # plotting length distributions\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    sns.histplot(premise_lengths, bins=50, kde=True, ax=axes[0], color='blue', log_scale=(False, True))\n",
    "    axes[0].set_title('Premise Length Distribution')\n",
    "    axes[0].set_xlabel('Number of Words')\n",
    "    axes[0].set_ylabel('Frequency')\n",
    "\n",
    "    sns.histplot(hypothesis_lengths, bins=50, kde=True, ax=axes[1], color='green', log_scale=(False, True))\n",
    "    axes[1].set_title('Hypothesis Length Distribution')\n",
    "    axes[1].set_xlabel('Number of Words')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "\n",
    "    fig.suptitle(f'Premise and Hypothesis Length Distribution in {title}')\n",
    "    plt.show()\n",
    "\n",
    "    if compare_length:\n",
    "        # plot premise vs hypothesis length scatter plot\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(premise_lengths, hypothesis_lengths, alpha=0.5, s=1)\n",
    "        plt.title('Premise vs Hypothesis Length')\n",
    "        plt.xlabel('Premise Length')\n",
    "        plt.ylabel('Hypothesis Length')\n",
    "        plt.yscale('log')\n",
    "        plt.xscale('log')\n",
    "        plt.grid(True, which=\"both\", ls=\"--\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Statistics about the regular dataset\n",
    "if print_statistics:\n",
    "  plot_labels_distribution(fever_dataset['train'], title=\"Fever Train Set\")\n",
    "  plot_lengths_distribution(fever_dataset['train'], title=\"Fever Train Set\", compare_length=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets structure: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'premise', 'hypothesis', 'label', 'wsd', 'srl'],\n",
      "        num_rows: 51086\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'premise', 'hypothesis', 'label', 'wsd', 'srl'],\n",
      "        num_rows: 2288\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'premise', 'hypothesis', 'label', 'wsd', 'srl'],\n",
      "        num_rows: 2287\n",
      "    })\n",
      "})\n",
      "\n",
      "SRL structure: \n",
      "dict_keys(['premise', 'hypothesis'])\n",
      "Tokens: \n",
      "{'index': 0, 'rawText': 'Deadpool'}\n",
      "{'index': 1, 'rawText': '('}\n",
      "{'index': 2, 'rawText': 'film'}\n",
      "{'index': 3, 'rawText': ')'}\n",
      "{'index': 4, 'rawText': '.'}\n",
      "{'index': 5, 'rawText': 'It'}\n",
      "{'index': 6, 'rawText': 'is'}\n",
      "{'index': 7, 'rawText': 'the'}\n",
      "{'index': 8, 'rawText': 'eighth'}\n",
      "{'index': 9, 'rawText': 'installment'}\n",
      "{'index': 10, 'rawText': 'and'}\n",
      "{'index': 11, 'rawText': 'a'}\n",
      "{'index': 12, 'rawText': 'spin'}\n",
      "{'index': 13, 'rawText': '-'}\n",
      "{'index': 14, 'rawText': 'off'}\n",
      "{'index': 15, 'rawText': 'in'}\n",
      "{'index': 16, 'rawText': 'the'}\n",
      "{'index': 17, 'rawText': 'X'}\n",
      "{'index': 18, 'rawText': '-'}\n",
      "{'index': 19, 'rawText': 'Men'}\n",
      "{'index': 20, 'rawText': 'film'}\n",
      "{'index': 21, 'rawText': 'series'}\n",
      "{'index': 22, 'rawText': ','}\n",
      "{'index': 23, 'rawText': 'and'}\n",
      "{'index': 24, 'rawText': 'stars'}\n",
      "{'index': 25, 'rawText': 'Ryan'}\n",
      "{'index': 26, 'rawText': 'Reynolds'}\n",
      "{'index': 27, 'rawText': 'as'}\n",
      "{'index': 28, 'rawText': 'the'}\n",
      "{'index': 29, 'rawText': 'titular'}\n",
      "{'index': 30, 'rawText': 'character'}\n",
      "{'index': 31, 'rawText': ','}\n",
      "{'index': 32, 'rawText': 'as'}\n",
      "{'index': 33, 'rawText': 'well'}\n",
      "{'index': 34, 'rawText': 'as'}\n",
      "{'index': 35, 'rawText': 'Morena'}\n",
      "{'index': 36, 'rawText': 'Baccarin'}\n",
      "{'index': 37, 'rawText': ','}\n",
      "{'index': 38, 'rawText': 'Ed'}\n",
      "{'index': 39, 'rawText': 'Skrein'}\n",
      "{'index': 40, 'rawText': ','}\n",
      "{'index': 41, 'rawText': 'T.'}\n",
      "{'index': 42, 'rawText': 'J.'}\n",
      "{'index': 43, 'rawText': 'Miller'}\n",
      "{'index': 44, 'rawText': ','}\n",
      "{'index': 45, 'rawText': 'Gina'}\n",
      "{'index': 46, 'rawText': 'Carano'}\n",
      "{'index': 47, 'rawText': ','}\n",
      "{'index': 48, 'rawText': 'Leslie'}\n",
      "{'index': 49, 'rawText': 'Uggams'}\n",
      "{'index': 50, 'rawText': ','}\n",
      "{'index': 51, 'rawText': 'Brianna'}\n",
      "{'index': 52, 'rawText': 'Hildebrand'}\n",
      "{'index': 53, 'rawText': ','}\n",
      "{'index': 54, 'rawText': 'and'}\n",
      "{'index': 55, 'rawText': 'Stefan'}\n",
      "{'index': 56, 'rawText': 'Kapičić'}\n",
      "{'index': 57, 'rawText': '.'}\n",
      "{'index': 58, 'rawText': 'T.'}\n",
      "{'index': 59, 'rawText': 'J.'}\n",
      "{'index': 60, 'rawText': 'Miller'}\n",
      "{'index': 61, 'rawText': '.'}\n",
      "{'index': 62, 'rawText': 'Miller'}\n",
      "{'index': 63, 'rawText': 'has'}\n",
      "{'index': 64, 'rawText': 'also'}\n",
      "{'index': 65, 'rawText': 'performed'}\n",
      "{'index': 66, 'rawText': 'in'}\n",
      "{'index': 67, 'rawText': 'such'}\n",
      "{'index': 68, 'rawText': 'films'}\n",
      "{'index': 69, 'rawText': 'as'}\n",
      "{'index': 70, 'rawText': 'Cloverfield'}\n",
      "{'index': 71, 'rawText': '('}\n",
      "{'index': 72, 'rawText': '2008'}\n",
      "{'index': 73, 'rawText': ')'}\n",
      "{'index': 74, 'rawText': ','}\n",
      "{'index': 75, 'rawText': 'She'}\n",
      "{'index': 76, 'rawText': \"'\"}\n",
      "{'index': 77, 'rawText': 's'}\n",
      "{'index': 78, 'rawText': 'Out'}\n",
      "{'index': 79, 'rawText': 'of'}\n",
      "{'index': 80, 'rawText': 'My'}\n",
      "{'index': 81, 'rawText': 'League'}\n",
      "{'index': 82, 'rawText': '('}\n",
      "{'index': 83, 'rawText': '2010'}\n",
      "{'index': 84, 'rawText': ')'}\n",
      "{'index': 85, 'rawText': ','}\n",
      "{'index': 86, 'rawText': 'Yogi'}\n",
      "{'index': 87, 'rawText': 'Bear'}\n",
      "{'index': 88, 'rawText': '3D'}\n",
      "{'index': 89, 'rawText': '('}\n",
      "{'index': 90, 'rawText': '2010'}\n",
      "{'index': 91, 'rawText': ')'}\n",
      "{'index': 92, 'rawText': ','}\n",
      "{'index': 93, 'rawText': 'How'}\n",
      "{'index': 94, 'rawText': 'to'}\n",
      "{'index': 95, 'rawText': 'Train'}\n",
      "{'index': 96, 'rawText': 'Your'}\n",
      "{'index': 97, 'rawText': 'Dragon'}\n",
      "{'index': 98, 'rawText': '('}\n",
      "{'index': 99, 'rawText': '2010'}\n",
      "{'index': 100, 'rawText': ')'}\n",
      "{'index': 101, 'rawText': ','}\n",
      "{'index': 102, 'rawText': 'How'}\n",
      "{'index': 103, 'rawText': 'to'}\n",
      "{'index': 104, 'rawText': 'Train'}\n",
      "{'index': 105, 'rawText': 'Your'}\n",
      "{'index': 106, 'rawText': 'Dragon'}\n",
      "{'index': 107, 'rawText': '2'}\n",
      "{'index': 108, 'rawText': '('}\n",
      "{'index': 109, 'rawText': '2014'}\n",
      "{'index': 110, 'rawText': ')'}\n",
      "{'index': 111, 'rawText': ','}\n",
      "{'index': 112, 'rawText': 'Transformers'}\n",
      "{'index': 113, 'rawText': ':'}\n",
      "{'index': 114, 'rawText': 'Age'}\n",
      "{'index': 115, 'rawText': 'of'}\n",
      "{'index': 116, 'rawText': 'Extinction'}\n",
      "{'index': 117, 'rawText': '('}\n",
      "{'index': 118, 'rawText': '2014'}\n",
      "{'index': 119, 'rawText': ')'}\n",
      "{'index': 120, 'rawText': ','}\n",
      "{'index': 121, 'rawText': 'Big'}\n",
      "{'index': 122, 'rawText': 'Hero'}\n",
      "{'index': 123, 'rawText': '6'}\n",
      "{'index': 124, 'rawText': '('}\n",
      "{'index': 125, 'rawText': '2014'}\n",
      "{'index': 126, 'rawText': ')'}\n",
      "{'index': 127, 'rawText': ','}\n",
      "{'index': 128, 'rawText': 'Deadpool'}\n",
      "{'index': 129, 'rawText': '('}\n",
      "{'index': 130, 'rawText': '2016'}\n",
      "{'index': 131, 'rawText': ')'}\n",
      "{'index': 132, 'rawText': ','}\n",
      "{'index': 133, 'rawText': 'and'}\n",
      "{'index': 134, 'rawText': 'Office'}\n",
      "{'index': 135, 'rawText': 'Chri'}\n",
      "{'index': 136, 'rawText': 'stmas'}\n",
      "{'index': 137, 'rawText': 'Party'}\n",
      "{'index': 138, 'rawText': '('}\n",
      "{'index': 139, 'rawText': '2016'}\n",
      "{'index': 140, 'rawText': ')'}\n",
      "{'index': 141, 'rawText': '.'}\n",
      "\n",
      "Annotations: \n",
      "tokenIndex:\t6\n",
      "verbatlas:\t{'frameName': 'COPULA', 'roles': [{'role': 'Theme', 'score': 1.0, 'span': [5, 6]}, {'role': 'Attribute', 'score': 1.0, 'span': [7, 22]}]}\n",
      "englishPropbank:\t{'frameName': 'be.01', 'roles': [{'role': 'ARG1', 'score': 1.0, 'span': [5, 6]}, {'role': 'ARG2', 'score': 1.0, 'span': [7, 22]}]}\n",
      "\n",
      "tokenIndex:\t24\n",
      "verbatlas:\t{'frameName': 'PERFORM', 'roles': [{'role': 'Agent', 'score': 1.0, 'span': [5, 6]}, {'role': 'Theme', 'score': 1.0, 'span': [25, 31]}, {'role': 'Predicative', 'score': 1.0, 'span': [32, 33]}]}\n",
      "englishPropbank:\t{'frameName': 'star.01', 'roles': [{'role': 'ARG1', 'score': 1.0, 'span': [5, 6]}, {'role': 'ARG2', 'score': 1.0, 'span': [25, 27]}, {'role': 'ARG2', 'score': 1.0, 'span': [27, 31]}, {'role': 'ARGM-PRD', 'score': 1.0, 'span': [32, 57]}]}\n",
      "\n",
      "tokenIndex:\t60\n",
      "verbatlas:\t{'frameName': 'COPULA', 'roles': []}\n",
      "englishPropbank:\t{'frameName': 'be.01', 'roles': [{'role': 'ARGM-ADJ', 'score': 1.0, 'span': [58, 59]}, {'role': 'ARGM-ADJ', 'score': 1.0, 'span': [59, 60]}]}\n",
      "\n",
      "tokenIndex:\t63\n",
      "verbatlas:\t{'frameName': 'AUXILIARY', 'roles': []}\n",
      "englishPropbank:\t{'frameName': 'have.01', 'roles': []}\n",
      "\n",
      "tokenIndex:\t65\n",
      "verbatlas:\t{'frameName': 'PERFORM', 'roles': [{'role': 'Agent', 'score': 1.0, 'span': [62, 63]}, {'role': 'Adverbial', 'score': 1.0, 'span': [64, 65]}, {'role': 'Location', 'score': 1.0, 'span': [66, 136]}]}\n",
      "englishPropbank:\t{'frameName': 'perform.01', 'roles': [{'role': 'ARG0', 'score': 1.0, 'span': [62, 63]}, {'role': 'ARGM-ADV', 'score': 1.0, 'span': [64, 65]}, {'role': 'ARGM-LOC', 'score': 1.0, 'span': [66, 136]}]}\n",
      "\n",
      "tokenIndex:\t95\n",
      "verbatlas:\t{'frameName': 'TEACH', 'roles': [{'role': 'Attribute', 'score': 1.0, 'span': [93, 94]}, {'role': 'Recipient', 'score': 1.0, 'span': [96, 98]}]}\n",
      "englishPropbank:\t{'frameName': 'train.01', 'roles': [{'role': 'ARGM-MNR', 'score': 1.0, 'span': [93, 94]}, {'role': 'ARG2', 'score': 1.0, 'span': [96, 98]}]}\n",
      "\n",
      "tokenIndex:\t104\n",
      "verbatlas:\t{'frameName': 'TEACH', 'roles': [{'role': 'Attribute', 'score': 1.0, 'span': [102, 103]}, {'role': 'Recipient', 'score': 1.0, 'span': [105, 108]}]}\n",
      "englishPropbank:\t{'frameName': 'train.01', 'roles': [{'role': 'ARGM-MNR', 'score': 1.0, 'span': [102, 103]}, {'role': 'ARG2', 'score': 1.0, 'span': [105, 108]}]}\n",
      "\n",
      "tokenIndex:\t137\n",
      "verbatlas:\t{'frameName': 'AUXILIARY', 'roles': []}\n",
      "englishPropbank:\t{'frameName': 'have.03', 'roles': []}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#@title Dataset structure\n",
    "\n",
    "if general_structure:\n",
    "  print(f\"Datasets structure: {fever_dataset}\")\n",
    "\n",
    "if show_ids:\n",
    "  print(f\"Train IDs: {fever_dataset['train']['id']}\")\n",
    "\n",
    "if show_labels:\n",
    "  print(f\"Train labels: {fever_dataset['train']['label']}\")\n",
    "\n",
    "\n",
    "if wsd_exploration:\n",
    "\n",
    "  print(f\"\\nWSD srtructure: \")\n",
    "  pretty_print_dict(fever_dataset['train'][42]['wsd'])\n",
    "\n",
    "  sample_range = len(fever_dataset['train'])\n",
    "  loop = tqdm(range(sample_range))\n",
    "\n",
    "  wsd_info = dict()\n",
    "  wsd_info['pos'] = dict()\n",
    "\n",
    "  for i in loop:\n",
    "\n",
    "    data =  fever_dataset['train'][i]\n",
    "    sample_id = data['id']\n",
    "\n",
    "    hypothesis = data['hypothesis']\n",
    "    hyp_wsd = data['wsd']['hypothesis']\n",
    "\n",
    "    for hyp_wsd_dict in hyp_wsd:\n",
    "      \n",
    "      pos  = hyp_wsd_dict['pos']\n",
    "      wsd_info['pos'][pos] = 1 if pos not in wsd_info['pos'] else wsd_info['pos'][pos] + 1\n",
    "\n",
    "  print(\"POS:\")\n",
    "  pretty_print_dict(wsd_info)\n",
    "\n",
    "  with open(info + \"wsd_pos.txt\", \"w\") as wsd_pos:\n",
    "    print(f\"Saving allPOS of the dataset into {info + 'wsd_pos.txt'}\")\n",
    "    for elem in wsd_info['pos']: wsd_pos.write(f\"{elem}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "if srl_exploration:\n",
    "  print(\"\\nSRL structure: \")\n",
    "  print(fever_dataset['train'][42]['srl'].keys())\n",
    "  # print(fever_dataset['train'][42]['srl']['hypothesis']['tokens'])\n",
    "  # print(fever_dataset['train'][42]['srl']['hypothesis']['annotations'])\n",
    "\n",
    "  print(\"Tokens: \")\n",
    "  for token in fever_dataset['train'][42]['srl']['premise']['tokens']:\n",
    "      print(token)\n",
    "\n",
    "  print(\"\\nAnnotations: \")\n",
    "  for annotation in fever_dataset['train'][42]['srl']['premise']['annotations']:\n",
    "      for key, value in annotation.items():\n",
    "          print(f\"{key}:\\t{value}\")\n",
    "      print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title SRL exploration: collect frame-names and roles \n",
    "\n",
    "def get_srl_info(dataset):\n",
    "\n",
    "  sample_range = len(dataset)\n",
    "  loop = tqdm(range(sample_range))\n",
    "\n",
    "  verbs_freqs = dict()\n",
    "  set_of_va_frames = dict() # verb atlas frames\n",
    "  set_of_pb_frames = dict() # prop bank frames\n",
    "  set_of_va_roles = set() # verb atlas frames\n",
    "  set_of_pb_roles = set() # prop bank frames\n",
    "\n",
    "  for i in loop:\n",
    "\n",
    "    data =  dataset[i]\n",
    "    sample_id = data['id']\n",
    "    \n",
    "    tokens = data['srl']['premise']['tokens']\n",
    "    annotations = data['srl']['premise']['annotations']\n",
    "\n",
    "    for annotation in annotations:\n",
    "\n",
    "      token_index = annotation['tokenIndex']\n",
    "      verb = tokens[token_index]['rawText']\n",
    "      verbs_freqs[verb] =  1 if verb not in  verbs_freqs else verbs_freqs[verb] + 1\n",
    "\n",
    "      vb_frame = annotation['verbatlas']['frameName']\n",
    "      pb_frame = annotation['englishPropbank']['frameName']\n",
    "\n",
    "      set_of_va_frames[vb_frame] = 1 if vb_frame not in set_of_va_frames else set_of_va_frames[vb_frame] + 1 \n",
    "      set_of_pb_frames[pb_frame] = 1 if pb_frame not in set_of_pb_frames else set_of_pb_frames[pb_frame] + 1 \n",
    "\n",
    "      va_roles = annotation['verbatlas']['roles']\n",
    "      pb_roles = annotation['englishPropbank']['roles']\n",
    "\n",
    "      for role in va_roles:\n",
    "        set_of_va_roles.add(role['role'])\n",
    "\n",
    "      for role in pb_roles:\n",
    "        set_of_pb_roles.add(role['role'])\n",
    "\n",
    "  return set_of_va_frames, set_of_pb_frames, set_of_va_roles, set_of_pb_roles, verbs_freqs\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_info:\n",
    "\n",
    "  set_of_va_frames, set_of_pb_frames, set_of_va_roles, set_of_pb_roles, verbs_freqs = get_srl_info(fever_dataset['train'])\n",
    "\n",
    "  verbs_freqs = sorted(verbs_freqs.items(), key=lambda item: item[1], reverse=True)\n",
    "  set_of_pb_frames = sorted(set_of_pb_frames.items(), key=lambda item: item[1], reverse=True)\n",
    "  set_of_va_frames = sorted(set_of_va_frames.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "  print(f\"Number of Verb Atlas frames: {len(set_of_va_frames)}\")\n",
    "  print(f\"Number of Verb Atlas roles: {len(set_of_va_roles)}\")\n",
    "\n",
    "  print(f\"Number of Propbank frames: {len(set_of_pb_frames)}\")\n",
    "  print(f\"Number of Propbank roles: {len(set_of_pb_roles)}\")\n",
    "\n",
    "  with open(info + \"va_roles.txt\", \"w\") as va_roles:\n",
    "    print(f\"Saving all Verb Atlas roles of the dataset into {info + 'va_roles.txt'}\")\n",
    "    for elem in set_of_va_roles: va_roles.write(f\"{elem}\\n\")\n",
    "\n",
    "  with open(info + \"va_frames.txt\", \"w\") as va_frames:\n",
    "    print(f\"Saving all Verb Atlas frames of the dataset into {info + 'va_frames.txt'}\")\n",
    "    for elem in set_of_va_frames: va_frames.write(f\"{elem}\\n\")\n",
    "\n",
    "\n",
    "  with open(info + \"pb_roles.txt\", \"w\") as pb_roles:\n",
    "    print(f\"Saving all Propbank roles of the dataset into {info + 'pb_roles.txt'}\")\n",
    "    for elem in set_of_pb_roles: pb_roles.write(f\"{elem}\\n\")\n",
    "\n",
    "\n",
    "  with open(info + \"pb_frames.txt\", \"w\") as pb_frames:\n",
    "    print(f\"Saving all Propbank frames of the dataset into {info + 'pb_frames.txt'}\")\n",
    "    for elem in set_of_pb_frames: pb_frames.write(f\"{elem}\\n\")\n",
    "\n",
    "  with open(info + \"verbs_freqs.txt\", \"w\") as verbs:\n",
    "    print(f\"Saving all verbs frequencies count into {info + 'verbs_freqs.txt'}\")\n",
    "    for elem in verbs_freqs: verbs.write(f\"{elem}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Augmentation\n",
    "The following prompt can be used to correct the grammar of a modified hypotesis so if just a not is added the phrase is transformed in negative form:\n",
    "\n",
    "\"Correct the grammar in the following inputs, rephrase the input if necessary to make them more accurate. Provide just the correct version, no explanation.\"\n",
    "\n",
    "Ask for:\n",
    "symmetric relation --> Marry\n",
    "antisymmetric relation --> Kill\n",
    "\n",
    "born\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Augmentation utils\n",
    "\n",
    "def get_sentence_from_span(tokens, span_begin, span_end):\n",
    "    sentence = \"\"\n",
    "    try: \n",
    "      sentence = \" \".join([tokens[index]['rawText']  for index in range(span_begin, span_end + 1)]) # if tokens[index]['rawText'] in names])\n",
    "    except:\n",
    "      sentence = \" \".join([tokens[index]['rawText'] for index in range(span_begin, span_end)]) #if tokens[index]['rawText'] in names])\n",
    "\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def join_strings_smartly(words):\n",
    "    \"\"\" Joins a list of words smartly:\n",
    "    - Adds spaces between words when appropriate.\n",
    "    - Avoids adding spaces before punctuation.\n",
    "    \"\"\"\n",
    "    punctuation = {'.', ',', ';', ':', '!', '?',')'}\n",
    "    result = words[0]\n",
    "    prev = result\n",
    "\n",
    "    for word in words[1:]:\n",
    "      if word in punctuation or \\\n",
    "        (\"'\" in prev) or \\\n",
    "        word.startswith(\"'\") or \\\n",
    "        (\".\" in prev and \".\" in word) or \\\n",
    "        (\"(\" in prev) :\n",
    "        # add word without space before\n",
    "        result += word\n",
    "      else:\n",
    "        # add with space before\n",
    "        result += \" \" + word\n",
    "      # keep track of previous word  \n",
    "      prev = word\n",
    "\n",
    "    return result\n",
    "\n",
    "def get_synset_from_id(synset_id):\n",
    "    if synset_id == 'O':\n",
    "        return None\n",
    "    try:\n",
    "        offset = int(''.join(filter(str.isdigit, synset_id)))\n",
    "        pos = synset_id[-1]\n",
    "        synset = wn.synset_from_pos_and_offset(pos, offset)\n",
    "        return synset\n",
    "    except:\n",
    "        print(\"exception\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "def get_related_word(synset, pos): \n",
    "    info = dict()\n",
    "\n",
    "    # Map POS tags to WordNet POS tags\n",
    "    pos_map = {\n",
    "        'NOUN': wn.NOUN,\n",
    "        'VERB': wn.VERB,\n",
    "        'ADJ': wn.ADJ,\n",
    "        'ADV': wn.ADV\n",
    "    }\n",
    "    \n",
    "    if pos not in pos_map:\n",
    "        return None \n",
    "    \n",
    "    # get hypernyms\n",
    "    hypernyms = synset.hypernyms()\n",
    "    if not hypernyms:\n",
    "        return None\n",
    "    hypernyms = synset.hypernyms()\n",
    "    # hypernym_words = set()\n",
    "    # for hypernym in hypernyms:\n",
    "    #     hypernym_words.update(hypernym.lemma_names())\n",
    "    info['hypernyms'] = [hypernyms[0].lemma_names()[0]] #list(hypernym_words)\n",
    "\n",
    "    # get synonyms \n",
    "    synonyms = synset.lemmas()\n",
    "    if not synonyms:\n",
    "        return None\n",
    "    info['synonyms'] = [synonym.name() for synonym in synonyms if synonym.name() != synset.lemmas()[0].name()]\n",
    "\n",
    "    return info\n",
    "\n",
    "\n",
    "def extract_names(wsd_data):\n",
    "    names = []\n",
    "    current_name = []\n",
    "\n",
    "    for entry in wsd_data:\n",
    "        if entry['pos'] == 'PROPN':\n",
    "            current_name.append(entry['text'])\n",
    "        else:\n",
    "            if current_name:\n",
    "                names.append(' '.join(current_name))\n",
    "                current_name = []\n",
    "\n",
    "    # catch any remaining name at the end\n",
    "    if current_name:\n",
    "        names.append(' '.join(current_name))\n",
    "    \n",
    "    return names\n",
    "\n",
    "\n",
    "def extract_partial_match_name(text, name_list):\n",
    "    # tokenize the input text\n",
    "    words = re.findall(r'\\b\\w+\\b', text)\n",
    "    names = []\n",
    "    \n",
    "    # iterate through each name in the name list\n",
    "    for name in name_list:\n",
    "        name_parts = name.split()\n",
    "\n",
    "        # check for partial match in the tokenized words\n",
    "        for i in range(len(words) - len(name_parts) + 1):\n",
    "            if words[i:i + len(name_parts)] == name_parts[:len(words[i:i + len(name_parts)])]:\n",
    "              names.append(name)\n",
    "              \n",
    "    if names: return names\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_dates(text):\n",
    "    # regular expression patterns for different date formats\n",
    "    patterns = [\n",
    "        r'\\b(\\d{4})\\b',  # matches a 4-digit year\n",
    "        r'\\b(\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4})\\b',  # matches dates like dd-mm-yyyy, dd/mm/yyyy, dd-mm-yy, dd/mm/yy\n",
    "        r'\\b(\\d{1,2} [A-Za-z]+ \\d{4})\\b',  # matches dates like 1 January 2020\n",
    "        r'\\b([A-Za-z]+ \\d{1,2}, \\d{4})\\b'  # matches dates like January 1, 2020\n",
    "    ]\n",
    "\n",
    "    months_list = [\n",
    "        \"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n",
    "        \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"\n",
    "    ]\n",
    "\n",
    "    pattern = re.compile(r'(?:(?P<day>\\d{1,2})(?:st|nd|rd|th)?[ ,]*)?(?:(?P<month>[A-Za-z]+)[ ,]*)?(?:(?P<year>\\d{4}))?')\n",
    "    matches = pattern.findall(text)\n",
    "    day, month, year = None, None, None\n",
    "\n",
    "    for match in matches:\n",
    "        if match[0]:\n",
    "            day = match[0]\n",
    "        if match[1]:\n",
    "            month = match[1]\n",
    "        if match[2]:\n",
    "            year = match[2]\n",
    "        \n",
    "        # more check to avoid error!\n",
    "        if day and not (1 <= int(day) <= 31):\n",
    "            day = None\n",
    "        if month and month not in months_list:\n",
    "            month = None\n",
    "            \n",
    "    return day, month, year\n",
    "\n",
    "def extract_locations(sentence):\n",
    "    locations = set()\n",
    "    entities =  nlp_spacy(sentence).ents\n",
    "    if entities:\n",
    "        found_target = False\n",
    "        for ent in entities:\n",
    "            if ent.label_ == \"GPE\":\n",
    "                found_target = True\n",
    "                locations.add(ent.text)\n",
    "    return locations\n",
    "\n",
    "\n",
    "movie_titles = [\n",
    "    \"John Wick: Chapter 2\",\n",
    "    \"On the Road (film)\",\n",
    "    \"Brave\",\n",
    "    \"Penny Dreadful\",\n",
    "    \"Snooki & Jwoww\",\n",
    "    \"Sons of Anarchy\",\n",
    "    \"The Sopranos\",\n",
    "    \"Thor: The Dark World\",\n",
    "    \"Winter Passing\",\n",
    "    \"Teen Wolf\",\n",
    "    \"Captain America: The Winter Soldier\",\n",
    "    \"The Belko Experiment\",\n",
    "    \"Fantastic Beasts and Where to Find Them\",\n",
    "    \"A Monster Calls\",\n",
    "    \"The Fate of the Furious\",\n",
    "    \"The Wolf of Wall Street (2013 film)\",\n",
    "    \"Tropico\",\n",
    "    \"Rescue Me\",\n",
    "    \"The Night Of\",\n",
    "    \"Lipstick Under My Burkha\",\n",
    "    \"The Promise\",\n",
    "    \"Sleeping Beauty\",\n",
    "    \"Mad Men\",\n",
    "    \"Avatar\",\n",
    "    \"Zootopia\",\n",
    "    \"Spider-Man\",\n",
    "    \"Enemy\",\n",
    "    \"Room\",\n",
    "    \"Cloud Atlas\",\n",
    "    \"Kong: Skull Island\",\n",
    "    \"Rick and Morty\",\n",
    "    \"Ink Master\",\n",
    "    \"Frenemies\",\n",
    "    \"Persuasion (2007 film)\",\n",
    "    \"Ballet Shoes\",\n",
    "    \"The Great Buck Howard\",\n",
    "    \"Schindler's List\",\n",
    "    \"Iron Man\",\n",
    "    \"The Illusionist\",\n",
    "    \"The Messenger\",\n",
    "    \"The Suite Life Movie\",\n",
    "    \"Wild\",\n",
    "    \"The Ren & Stimpy Show\",\n",
    "    \"Johnny Mnemonic\",\n",
    "    \"Denial (2016 film)\",\n",
    "    \"Black Sails\",\n",
    "    \"The Breakfast Club\",\n",
    "    \"Modern Family\",\n",
    "    \"Interstellar\",\n",
    "    \"To the Bone\",\n",
    "    \"Prison Break\",\n",
    "    \"Game of Thrones (season 3)\",\n",
    "    \"Line of Duty\",\n",
    "    \"In the Heart of the Sea\",\n",
    "    \"Oz the Great and Powerful\",\n",
    "    \"Attack on Titan\",\n",
    "    \"Her\",\n",
    "    \"The Carmichael Show\",\n",
    "    \"The Leftovers\",\n",
    "    \"Short Term 12\",\n",
    "    \"Stephanie Daley\",\n",
    "    \"Fargo\",\n",
    "    \"BoJack Horseman\",\n",
    "    \"New Girl\",\n",
    "    \"Glee\",\n",
    "    \"Turn: Washington's Spies\",\n",
    "    \"X-Men: Days of Future Past\",\n",
    "    \"Miss Peregrine's Home for Peculiar Children\",\n",
    "    \"Ghostbusters\",\n",
    "    \"Famous in Love\",\n",
    "    \"Legion\",\n",
    "    \"Spider-Man 3\",\n",
    "    \"Deadpool (film)\",\n",
    "    \"Doctor Who\",\n",
    "    \"San Junipero\",\n",
    "    \"Outlander (TV series)\",\n",
    "    \"Elementary\",\n",
    "    \"The Shield\",\n",
    "    \"Broadchurch\",\n",
    "    \"Fairy Tail\",\n",
    "    \"Major Barbara\",\n",
    "    \"American Horror Story\",\n",
    "    \"Trolls\",\n",
    "    \"Harry Potter\",\n",
    "    \"Whiplash\",\n",
    "    \"Split (2016 American film)\",\n",
    "    \"How to Be\",\n",
    "    \"Cars Toons\",\n",
    "    \"Little Miss Sunshine\",\n",
    "    \"Naruto\",\n",
    "    \"Horrible Bosses\",\n",
    "    \"There Will Be Blood\",\n",
    "    \"Beauty and the Beast\",\n",
    "    \"Grey's Anatomy\",\n",
    "    \"Futurama\",\n",
    "    \"The Strain\",\n",
    "    \"The Avengers\",\n",
    "    \"The Vampire Diaries\",\n",
    "    \"True Detective\",\n",
    "    \"Teen Wolf's sixth season\",\n",
    "    \"Interview\",\n",
    "    \"The Supernatural\",\n",
    "    \"The Girl on the Train\",\n",
    "    \"Interstellar\",\n",
    "    \"Guardians of the Galaxy\",\n",
    "    \"Miss Peregrine's Home for Peculiar Children\",\n",
    "    \"Love & Friendship\",\n",
    "    \"Goliyon Ki Raasleela Ram-Leela\"\n",
    "]\n",
    "\n",
    "def get_movie_title(sentence):\n",
    "    for title in movie_titles:\n",
    "        if re.search(r'\\b' + re.escape(title) + r'\\b', sentence):\n",
    "            return title\n",
    "\n",
    "# add new samples to the dataset\n",
    "# filtered_dataset = fever_dataset['train'].filter(lambda example: 'is a ' in example['premise'].lower()) # or 'is a' in example['hypothesis'].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/51086 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51086/51086 [01:08<00:00, 740.71it/s]\n"
     ]
    }
   ],
   "source": [
    "#@title Build relational graph\n",
    "\n",
    "# dataset = filtered_dataset\n",
    "dataset = fever_dataset['train']\n",
    "\n",
    "sample_range = len(dataset)\n",
    "loop = tqdm(range(sample_range))\n",
    "\n",
    "accetable_verbs = ['marry.01', 'premiere.01']\n",
    "\n",
    "relational_graph = dict()\n",
    "old_max_span = 1_000_000\n",
    "\n",
    "for i in loop:\n",
    "\n",
    "  data =  dataset[i]\n",
    "  sample_id = data['id']\n",
    "  premise = data['premise']\n",
    "  hypothesis = data['hypothesis']\n",
    "  # print(f\"premise: {premise}\")\n",
    "  \n",
    "  # srl info\n",
    "  tokens = data['srl']['premise']['tokens']\n",
    "  annotations = data['srl']['premise']['annotations']\n",
    "\n",
    "  # wsd info\n",
    "  wsd = data['wsd']['premise']\n",
    "  proper_nouns = extract_names(wsd)\n",
    "\n",
    "  hp_wsd = data['wsd']['hypothesis']\n",
    "  hp_proper_nouns = extract_names(hp_wsd)\n",
    "\n",
    "  # hp_wsd = data['wsd']['hypothesis']\n",
    "  # hp_proper_nouns = extract_names(hp_wsd)\n",
    "  # print(proper_nouns)\n",
    "\n",
    "  for annotation in annotations:\n",
    "\n",
    "    token_index = annotation['tokenIndex']\n",
    "    verb = tokens[token_index]['rawText']\n",
    "\n",
    "    # frame = annotation['verbatlas']['frameName']\n",
    "    frame = annotation['englishPropbank']['frameName']\n",
    "\n",
    "    if verb[0].isupper(): continue  # because usually capital letter verbs are movie titles\n",
    "    if frame not in accetable_verbs: continue\n",
    "    if frame not in relational_graph: relational_graph[frame] = dict()\n",
    "    # print(premise)\n",
    "\n",
    "    # roles = annotation['verbatlas']['roles']\n",
    "    roles = annotation['englishPropbank']['roles']\n",
    "\n",
    "    try:\n",
    "      span_begin = roles[0]['span'][0]\n",
    "      span_end = roles[-1]['span'][1]\n",
    "\n",
    "    except:\n",
    "      # print(roles)\n",
    "      continue\n",
    "\n",
    "    if span_begin > 0 and span_begin < old_max_span: \n",
    "      span_begin = 0\n",
    "      old_max_span = span_end\n",
    "\n",
    "    sentence = get_sentence_from_span(tokens, span_begin, span_end)\n",
    "\n",
    "\n",
    "    if frame in ['premiere.01'] and (\"premiered in \" in premise or \"premiered at \" in premise or \"premiered on \" in premise):\n",
    "\n",
    "      # from sentence extract movie title\n",
    "  \n",
    "      title = get_movie_title(hypothesis)\n",
    "      if not title: continue\n",
    "\n",
    "      # print(sentence)\n",
    "      span_1_l, span_2_l, span_1_d, span_2_d  = None, None, None, None\n",
    "      for role in roles:\n",
    "        if role['span'][1] > span_end : \n",
    "          # print(sentence)\n",
    "          # print(span_end)\n",
    "          # print(role)\n",
    "          break\n",
    "\n",
    "        if role['role'] in ['ARGM-LOC', 'R-ARGM-LOC', 'C-ARGM-LOC']: \n",
    "          span_1_l = role['span'][0]\n",
    "          span_2_l = role['span'][1]\n",
    "\n",
    "        if role['role'] in ['ARGM-TMP', 'R-ARGM-TMP']: \n",
    "          span_1_d = role['span'][0]\n",
    "          span_2_d = role['span'][1] \n",
    "\n",
    "      # from sentence extrat location and date\n",
    "      if  span_1_l and span_2_l:\n",
    "        location_sentence = get_sentence_from_span(tokens, span_1_l, span_2_l)\n",
    "        locations = extract_locations(location_sentence)\n",
    "      else: \n",
    "        locations = set()\n",
    "      \n",
    "      locations = list(locations)\n",
    "    \n",
    "      if span_1_d and span_2_d:\n",
    "        date_sentence =  get_sentence_from_span(tokens, span_1_d, span_2_d)\n",
    "        date = extract_dates(date_sentence)\n",
    "      else:\n",
    "        date = []\n",
    "        \n",
    "      # add nodes to the graph\n",
    "      if title not in relational_graph[frame]: \n",
    "        relational_graph[frame][title] = dict()\n",
    "        relational_graph[frame][title]['locations'] = locations\n",
    "        relational_graph[frame][title]['date'] = [date]\n",
    "        relational_graph[frame][title]['id'] = [sample_id]\n",
    "\n",
    "      else: \n",
    "        if set(locations).intersection(set(relational_graph[frame][title]['locations'])) == set(): \n",
    "          relational_graph[frame][title]['locations'] += locations\n",
    "\n",
    "        if date not in relational_graph[frame][title]['date']:\n",
    "          relational_graph[frame][title]['date'].append(date)\n",
    "\n",
    "        if sample_id not in relational_graph[frame][title]['id']:\n",
    "          relational_graph[frame][title]['id'].append(sample_id)\n",
    "\n",
    "\n",
    "    if frame in  ['marry.01']: \n",
    "      \n",
    "      # print(sentence)\n",
    "      # print(hypothesis)\n",
    "      main = extract_partial_match_name(hypothesis, hp_proper_nouns)\n",
    "      targets = extract_partial_match_name(sentence, proper_nouns)\n",
    "\n",
    "      if main: main = main[0]\n",
    "      # print(hp_proper_nouns)\n",
    "      # print(main)\n",
    "\n",
    "      if not targets: continue\n",
    "      targets = list(set(targets))\n",
    "\n",
    "      date = []\n",
    "      if \"married in\" in premise:\n",
    "        span_1_d, span_2_d  = None, None\n",
    "        for role in roles:\n",
    "          if role['span'][1] > span_end : break\n",
    "\n",
    "          if role['role'] in ['ARGM-TMP', 'R-ARGM-TMP']: \n",
    "            span_1_d = role['span'][0]\n",
    "            span_2_d = role['span'][1] \n",
    "\n",
    "        if span_1_d and span_2_d:\n",
    "          date_sentence =  get_sentence_from_span(tokens, span_1_d, span_2_d)\n",
    "          date = extract_dates(date_sentence)\n",
    "\n",
    "      if main in targets: \n",
    "        targets.remove(main)\n",
    "\n",
    "      if main not in relational_graph[frame]:\n",
    "         relational_graph[frame][main] = dict()\n",
    "         relational_graph[frame][main]['spouses'] = targets\n",
    "         relational_graph[frame][main]['date'] = [date]\n",
    "         relational_graph[frame][main]['id'] = [sample_id]\n",
    "\n",
    "      else:\n",
    "      \n",
    "        if targets not in relational_graph[frame][main]['spouses']:\n",
    "          relational_graph[frame][main]['date'].append(date)\n",
    "\n",
    "        if date not in relational_graph[frame][main]['date']:\n",
    "          relational_graph[frame][main]['date'].append(date)\n",
    "\n",
    "        if sample_id not in relational_graph[frame][main]['id']:\n",
    "          relational_graph[frame][main]['id'].append(sample_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "premiere.01: \n",
      "    John Wick: Chapter 2: \n",
      "        locations: ['Los Angeles']\n",
      "        date: [('30', 'January', '2017')]\n",
      "        id: ['138117', '48551', '9366', '138368', '61964', '97247', '9367']\n",
      "    Brave: \n",
      "        locations: []\n",
      "        date: [('10', 'June', '2012')]\n",
      "        id: ['209148', '209129', '209162']\n",
      "    Penny Dreadful: \n",
      "        locations: []\n",
      "        date: [('9', None, None), ('11', 'May', '2014')]\n",
      "        id: ['113668', '88185', '145475', '33511', '135923', '40973', '136982', '63647', '53104', '149528', '147369']\n",
      "    Snooki & Jwoww: \n",
      "        locations: []\n",
      "        date: [('22', 'October', '2013'), ('5', 'November', '2014'), ('8', 'January', '2013')]\n",
      "        id: ['183071', '183054', '183052', '183061', '183044', '183068', '183064', '183060']\n",
      "    Sons of Anarchy: \n",
      "        locations: []\n",
      "        date: [('3', 'September', '2008'), ('9', 'September', '2014'), ('9', 'December', '2014')]\n",
      "        id: ['57', '13852', '108672', '73620', '99584', '51560', '58', '61340', '116506', '82239']\n",
      "    The Sopranos: \n",
      "        locations: ['the United States']\n",
      "        date: [('10', 'January', '1999')]\n",
      "        id: ['28225', '24918', '12462', '139320', '116467', '70496', '9562', '96381', '135676', '7280', '57859', '136736', '8314', '134122', '75675']\n",
      "    Thor: The Dark World: \n",
      "        locations: ['London']\n",
      "        date: [('22', 'October', '2013')]\n",
      "        id: ['32278', '82503', '133505']\n",
      "    The Ren & Stimpy Show: \n",
      "        locations: []\n",
      "        date: [('11', None, '1991')]\n",
      "        id: ['121004', '22668', '53149', '143038', '6828', '97476']\n",
      "    Winter Passing: \n",
      "        locations: []\n",
      "        date: [(None, None, '2005')]\n",
      "        id: ['214644', '214654', '214659', '214658']\n",
      "    Teen Wolf: \n",
      "        locations: []\n",
      "        date: [(None, None, '2011'), ('15', 'November', '2016')]\n",
      "        id: ['84340', '30948', '16867', '152049', '23449', '1540', '110049', '34796', '62643', '142833']\n",
      "    Captain America: The Winter Soldier: \n",
      "        locations: ['Los Angeles']\n",
      "        date: [('13', 'March', '2014')]\n",
      "        id: ['217436', '217445', '217439', '217438', '217441', '217447', '217433']\n",
      "    The Belko Experiment: \n",
      "        locations: []\n",
      "        date: [('10', None, '2016')]\n",
      "        id: ['35193', '131146', '147434', '37460', '2094', '133762', '118826', '35444', '75912', '56118', '50953']\n",
      "    Fantastic Beasts and Where to Find Them: \n",
      "        locations: ['New York City']\n",
      "        date: [('10', None, '2016')]\n",
      "        id: ['58443', '34332', '32343', '111488', '32342', '145482', '75338', '2814', '38428', '143197', '73157', '153997', '113084', '36946', '86337', '106356', '100660', '151390', '3741', '60155', '29776', '55524', '109707', '22369', '66007']\n",
      "    A Monster Calls: \n",
      "        locations: []\n",
      "        date: [('10', 'September', '2016')]\n",
      "        id: ['122156', '125241', '97020', '131998', '118782']\n",
      "    Prison Break: \n",
      "        locations: []\n",
      "        date: [('4', 'April', '2017')]\n",
      "        id: ['64233', '83960', '121566', '119476', '81442', '123630', '143795', '157857', '150302', '59999', '109660', '71369', '70324', '153266', '144960', '72534', '26456', '34948']\n",
      "    The Strain: \n",
      "        locations: ['Texas', 'Austin']\n",
      "        date: [('13', 'July', '2014'), ('12', 'July', '2015'), ('28', 'August', '2016'), ('16', 'July', '2017'), (None, 'June', '2014')]\n",
      "        id: ['82642', '198200', '63615', '118187', '183835', '139049', '183845', '198194', '107552', '198198', '183844', '198203', '198195', '183851', '183840']\n",
      "    Tropico: \n",
      "        locations: []\n",
      "        date: [(None, 'December', '2013')]\n",
      "        id: ['6328']\n",
      "    Rescue Me: \n",
      "        locations: []\n",
      "        date: [('21', None, '2004')]\n",
      "        id: ['166131', '166128', '166102', '166126', '166115', '166108', '166124', '166109']\n",
      "    Lipstick Under My Burkha: \n",
      "        locations: ['Tokyo']\n",
      "        date: [[]]\n",
      "        id: ['146363', '96156', '73696', '46032', '34068', '122803']\n",
      "    The Promise: \n",
      "        locations: []\n",
      "        date: [('11', 'September', '2016')]\n",
      "        id: ['73489', '506', '29797', '44071', '95424', '152759', '122630', '142023', '29796', '24746', '74956']\n",
      "    Sleeping Beauty: \n",
      "        locations: ['US']\n",
      "        date: [(None, None, None), ('2', None, '2011')]\n",
      "        id: ['147944', '156382', '36530', '33490', '69977', '66204', '99616']\n",
      "    Mad Men: \n",
      "        locations: []\n",
      "        date: [('19', 'July', '2007')]\n",
      "        id: ['151807', '149499', '8978']\n",
      "    There Will Be Blood: \n",
      "        locations: []\n",
      "        date: [[]]\n",
      "        id: ['87259', '152464']\n",
      "    Avatar: \n",
      "        locations: ['London']\n",
      "        date: [(None, None, '2009')]\n",
      "        id: ['141791', '104519', '59621', '115904', '152457', '90547', '143669', '81504']\n",
      "    The Vampire Diaries: \n",
      "        locations: []\n",
      "        date: [('10', None, '2009')]\n",
      "        id: ['39495', '126593', '11176', '90481', '78538', '21162', '11177', '45684', '125656', '34107', '174805', '48998']\n",
      "    Cloud Atlas: \n",
      "        locations: []\n",
      "        date: [('8', None, '2012')]\n",
      "        id: ['216621', '216633', '216627', '216646', '216622', '216647', '216630', '216631', '216626']\n",
      "    Kong: Skull Island: \n",
      "        locations: ['London']\n",
      "        date: [('28', 'February', '2017')]\n",
      "        id: ['10282']\n",
      "    Rick and Morty: \n",
      "        locations: []\n",
      "        date: [('26', 'July', '2015')]\n",
      "        id: ['2395', '45505', '113031', '53304', '2396', '119451', '18977', '8798']\n",
      "    Ink Master: \n",
      "        locations: ['Spike']\n",
      "        date: [('17', 'January', '2012'), ('23', 'June', '2015'), ('23', None, '2016'), ('23', None, None), ('1', 'March', '2016')]\n",
      "        id: ['87468', '81581', '6795', '6796', '51313', '44746', '1651', '76366', '10227']\n",
      "    Frenemies: \n",
      "        locations: ['Canada', 'the United States']\n",
      "        date: [[], ('13', None, '2012')]\n",
      "        id: ['177580', '177565', '177562', '177577', '177579', '177578', '177544', '177584', '177553']\n",
      "    Room: \n",
      "        locations: []\n",
      "        date: [('4', None, '2015')]\n",
      "        id: ['2569', '2570', '65428', '45931', '66629', '15924', '152585', '23576']\n",
      "    Ballet Shoes: \n",
      "        locations: []\n",
      "        date: [[]]\n",
      "        id: ['205292', '205298', '205294', '205299', '205313', '205323', '205319']\n",
      "    New Girl: \n",
      "        locations: []\n",
      "        date: [('20', 'September', '2011'), ('20', 'September', '2016')]\n",
      "        id: ['188861', '188837', '110251', '97833', '157197', '12595', '188858', '133263']\n",
      "    Grey's Anatomy: \n",
      "        locations: []\n",
      "        date: [('27', 'March', '2005'), ('22', 'September', '2016')]\n",
      "        id: ['72977', '103880', '140993', '90853', '101815', '106340', '3934', '109404']\n",
      "    Horrible Bosses: \n",
      "        locations: ['Los Angeles']\n",
      "        date: [('30', 'June', '2011')]\n",
      "        id: ['166284', '166253']\n",
      "    The Breakfast Club: \n",
      "        locations: ['Los Angeles']\n",
      "        date: [('7', 'February', '1985')]\n",
      "        id: ['89855', '114646', '108412', '103411', '156948', '102275']\n",
      "    Broadchurch: \n",
      "        locations: []\n",
      "        date: [('5', 'January', '2015'), ('4', 'March', '2013'), ('27', 'February', '2017')]\n",
      "        id: ['149653', '128892', '41324', '14958', '105472', '116869']\n",
      "    Modern Family: \n",
      "        locations: []\n",
      "        date: [('23', 'September', '2009'), ('21', 'September', '2016')]\n",
      "        id: ['186960', '77528', '75907', '186968', '108832', '78074', '125475', '94394', '69092', '96295', '123423']\n",
      "    Wild: \n",
      "        locations: []\n",
      "        date: [('29', 'August', '2014')]\n",
      "        id: ['151765', '61474', '8293', '12393']\n",
      "    The Fate of the Furious: \n",
      "        locations: ['Berlin']\n",
      "        date: [('4', None, '2017')]\n",
      "        id: ['220892', '220895', '220906', '220894', '220907', '220891', '220887']\n",
      "    Zootopia: \n",
      "        locations: ['Belgium']\n",
      "        date: [('13', 'February', '2016')]\n",
      "        id: ['38710', '86561', '153943', '102265', '12107', '86320']\n",
      "    Spider-Man: \n",
      "        locations: ['Philippines', 'Tokyo']\n",
      "        date: [('30', 'April', '2002'), ('16', None, '2007')]\n",
      "        id: ['78132', '225075', '78965', '146774', '52001', '18061', '116601', '53900', '15927', '103122', '104933', '58475']\n",
      "    Enemy: \n",
      "        locations: []\n",
      "        date: [('8', 'September', '2013')]\n",
      "        id: ['161583', '161586', '176871', '161563']\n",
      "    The Night Of: \n",
      "        locations: []\n",
      "        date: [('10', None, '2016'), ('24', 'June', '2016')]\n",
      "        id: ['97351', '77049', '9256', '9257', '222872', '139909']\n",
      "    Johnny Mnemonic: \n",
      "        locations: []\n",
      "        date: [('15', 'April', '1995')]\n",
      "        id: ['104028', '128952', '26988', '31859', '48531', '149846', '131917', '8052', '89466', '3158']\n",
      "    Futurama: \n",
      "        locations: []\n",
      "        date: [(None, None, '1999')]\n",
      "        id: ['33396', '71258', '29646']\n",
      "    The Illusionist: \n",
      "        locations: []\n",
      "        date: [[]]\n",
      "        id: ['48932', '125718', '12694', '202390', '74309', '107728', '142158']\n",
      "    Fairy Tail: \n",
      "        locations: ['Tokyo']\n",
      "        date: [[]]\n",
      "        id: ['78819', '45676', '89357', '43745', '64530', '69372']\n",
      "    Black Sails: \n",
      "        locations: []\n",
      "        date: [('24', 'January', '2015'), [], ('29', 'January', '2017')]\n",
      "        id: ['173806', '219729', '219715']\n",
      "    In the Heart of the Sea: \n",
      "        locations: ['New York City']\n",
      "        date: [('7', None, '2015')]\n",
      "        id: ['71758', '99823', '26847', '7069', '124675', '96623', '107483', '19208']\n",
      "    The Shield: \n",
      "        locations: ['the United States']\n",
      "        date: [('12', 'March', '2002')]\n",
      "        id: ['79690', '120556', '129773', '115809', '122731', '67535', '27872', '91102']\n",
      "    The Messenger: \n",
      "        locations: []\n",
      "        date: [[]]\n",
      "        id: ['143914', '75936', '45524']\n",
      "    The Supernatural: \n",
      "        locations: []\n",
      "        date: [('13', 'September', '2005')]\n",
      "        id: ['19849', '135471', '95037', '155154', '148380', '19948']\n",
      "    The Suite Life Movie: \n",
      "        locations: []\n",
      "        date: [('25', None, '2011')]\n",
      "        id: ['91601']\n",
      "    Iron Man: \n",
      "        locations: ['Sydney']\n",
      "        date: [('14', 'April', '2008')]\n",
      "        id: ['22541', '3484']\n",
      "    Oz the Great and Powerful: \n",
      "        locations: []\n",
      "        date: [('14', 'February', '2013')]\n",
      "        id: ['193941', '193925', '193929', '193959', '193921', '193965', '193938', '193930', '193957', '193924', '193946', '193931', '193958']\n",
      "    Attack on Titan: \n",
      "        locations: []\n",
      "        date: [(None, 'April', '2017')]\n",
      "        id: ['45449', '31126', '31127', '111618', '21998', '12623', '118437']\n",
      "    X-Men: Days of Future Past: \n",
      "        locations: ['New York City']\n",
      "        date: [('10', 'May', '2014')]\n",
      "        id: ['115610', '2300']\n",
      "    Legion: \n",
      "        locations: []\n",
      "        date: [('8', 'February', None)]\n",
      "        id: ['229017', '229038', '176793', '229031', '229044', '44873', '229019', '229030', '229045', '141902', '229042', '229028', '229025', '20674']\n",
      "    Beauty and the Beast: \n",
      "        locations: ['London']\n",
      "        date: [('23', 'February', '2017')]\n",
      "        id: ['81659', '17529', '22550']\n",
      "    Famous in Love: \n",
      "        locations: []\n",
      "        date: [('18', 'April', '2017')]\n",
      "        id: ['191605', '191598', '191622', '191600', '191592']\n",
      "    Trolls: \n",
      "        locations: []\n",
      "        date: [('8', 'October', '2016')]\n",
      "        id: ['75163', '209596', '209607']\n",
      "    The Great Buck Howard: \n",
      "        locations: []\n",
      "        date: [('18', 'January', '2008')]\n",
      "        id: ['152766']\n",
      "    Glee: \n",
      "        locations: []\n",
      "        date: [('9', 'January', '2015'), ('19', 'May', '2009')]\n",
      "        id: ['175833', '8489', '16778', '175835', '175828', '175850', '33851', '175832', '175849']\n",
      "    Elementary: \n",
      "        locations: []\n",
      "        date: [('27', 'September', '2012'), []]\n",
      "        id: ['212653', '212635', '212659', '68506']\n",
      "    The Avengers: \n",
      "        locations: ['Hollywood']\n",
      "        date: [('11', 'April', '2012')]\n",
      "        id: ['67316', '103995']\n",
      "    Schindler's List: \n",
      "        locations: ['Washington', 'D.C.']\n",
      "        date: [('30', 'November', '1993')]\n",
      "        id: ['121604', '57450', '17473', '65897', '51721']\n",
      "    The Carmichael Show: \n",
      "        locations: []\n",
      "        date: [('26', 'August', '2015'), ('31', 'May', '2017')]\n",
      "        id: ['221322', '221326', '221276', '221262', '221325']\n",
      "    The Leftovers: \n",
      "        locations: []\n",
      "        date: [('29', 'June', '2014'), ('4', 'October', '2015'), ('16', 'April', '2017')]\n",
      "        id: ['106677', '120444', '152674', '103788']\n",
      "    Short Term 12: \n",
      "        locations: []\n",
      "        date: [('10', None, '2013')]\n",
      "        id: ['201973', '202001', '201974']\n",
      "    Stephanie Daley: \n",
      "        locations: []\n",
      "        date: [[]]\n",
      "        id: ['90198', '88740']\n",
      "    BoJack Horseman: \n",
      "        locations: ['Netflix']\n",
      "        date: [('22', 'August', '2014'), ('19', 'December', None)]\n",
      "        id: ['90326', '23700', '23932', '41371', '8263']\n",
      "    True Detective: \n",
      "        locations: []\n",
      "        date: [('12', 'January', '2014')]\n",
      "        id: ['20419', '95113', '38833']\n",
      "    Doctor Who: \n",
      "        locations: ['Canada', 'Alberta', 'Edmonton']\n",
      "        date: [('12', None, '1996'), ('15', None, '2017')]\n",
      "        id: ['108729', '22198', '76267']\n",
      "    Ghostbusters: \n",
      "        locations: ['Los Angeles']\n",
      "        date: [('9', None, '2016')]\n",
      "        id: ['55257', '23667', '54990', '115596', '128384']\n",
      "    Whiplash: \n",
      "        locations: []\n",
      "        date: [('16', 'January', '2014')]\n",
      "        id: ['28147', '16936', '88818']\n",
      "    Interstellar: \n",
      "        locations: ['Los Angeles']\n",
      "        date: [('26', None, '2014')]\n",
      "        id: ['79685', '117012', '157951']\n",
      "    San Junipero: \n",
      "        locations: ['Netflix']\n",
      "        date: [('21', 'October', '2016')]\n",
      "        id: ['101053', '52683', '21540']\n",
      "    To the Bone: \n",
      "        locations: []\n",
      "        date: [('22', 'January', '2017')]\n",
      "        id: ['199149', '199147', '199145']\n",
      "    How to Be: \n",
      "        locations: []\n",
      "        date: [('18', 'January', '2008')]\n",
      "        id: ['221544']\n",
      "    Major Barbara: \n",
      "        locations: []\n",
      "        date: [(None, None, '1905')]\n",
      "        id: ['161073']\n",
      "    Turn: Washington's Spies: \n",
      "        locations: []\n",
      "        date: [('13', 'April', '2015'), ('25', 'April', '2016')]\n",
      "        id: ['220597', '220592']\n",
      "    American Horror Story: \n",
      "        locations: []\n",
      "        date: [('7', 'October', '2015')]\n",
      "        id: ['39305', '126598', '10744', '19328']\n",
      "    Her: \n",
      "        locations: []\n",
      "        date: [('12', 'October', '2013')]\n",
      "        id: ['142587', '85744']\n",
      "    Little Miss Sunshine: \n",
      "        locations: []\n",
      "        date: [('20', 'January', '2006')]\n",
      "        id: ['21556', '19507', '70461', '32603']\n",
      "    Fargo: \n",
      "        locations: []\n",
      "        date: [('19', 'April', '2017')]\n",
      "        id: ['8528', '74358']\n",
      "    Naruto: \n",
      "        locations: []\n",
      "        date: [('10', 'September', '2005')]\n",
      "        id: ['51407', '31064', '29350', '51406']\n",
      "    Line of Duty: \n",
      "        locations: []\n",
      "        date: [('26', 'June', '2012')]\n",
      "        id: ['41466', '68951', '6552', '101605', '17193', '55751']\n",
      "    Harry Potter: \n",
      "        locations: ['Chicago']\n",
      "        date: [(None, None, '2009'), (None, 'November', '2016')]\n",
      "        id: ['23313']\n",
      "    Interview: \n",
      "        locations: []\n",
      "        date: [(None, None, '2007')]\n",
      "        id: ['136444']\n",
      "    Cars Toons: \n",
      "        locations: []\n",
      "        date: [[]]\n",
      "        id: ['93277']\n",
      "    Miss Peregrine's Home for Peculiar Children: \n",
      "        locations: ['Texas', 'Austin']\n",
      "        date: [('25', None, '2016')]\n",
      "        id: ['218405', '116509', '218401']\n",
      "    Guardians of the Galaxy: \n",
      "        locations: ['Hollywood']\n",
      "        date: [('21', 'July', '2014')]\n",
      "        id: ['168658']\n",
      "    The Girl on the Train: \n",
      "        locations: ['London']\n",
      "        date: [('20', None, '2016')]\n",
      "        id: ['169413']\n",
      "    Goliyon Ki Raasleela Ram-Leela: \n",
      "        locations: []\n",
      "        date: [(None, None, None)]\n",
      "        id: ['207641']\n",
      "    Love & Friendship: \n",
      "        locations: []\n",
      "        date: [(None, 'January', '2016')]\n",
      "        id: ['190883']\n",
      "marry.01: \n",
      "    Wyatt Earp: \n",
      "        spouses: ['Earp', 'Urilla Sutherland Earp']\n",
      "        date: [[], [], [], [], [], [], [], []]\n",
      "        id: ['30166', '124003', '19664', '140605', '39026', '18407', '140570', '114675']\n",
      "    Paul McCartney: \n",
      "        spouses: []\n",
      "        date: [[], [], [], [], [], [], [], []]\n",
      "        id: ['52015', '149441', '7983', '135818', '21689', '157227', '47751', '62218']\n",
      "    Linda McCartney: \n",
      "        spouses: ['Paul McCartney', 'Linda Louise', 'April', 'Lady McCartney', 'Beatles', 'September']\n",
      "        date: [[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
      "        id: ['117931', '212352', '32317', '139088', '71073', '9274', '67951', '78468', '9275', '87083', '112671', '212351']\n",
      "    Jennifer Garner: \n",
      "        spouses: ['Garner', 'Scott Foley']\n",
      "        date: [[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
      "        id: ['229394', '4974', '71362', '61558', '229389', '229391', '229401', '229396', '229397', '4975', '133008', '57188']\n",
      "    Ellen Pompeo: \n",
      "        spouses: ['Pompeo', 'Chris Ivery']\n",
      "        date: [[], [], [], [], [], []]\n",
      "        id: ['89086', '114846', '137940', '61666', '83319', '118335']\n",
      "    Harald V: \n",
      "        spouses: ['Harald', 'Norway', 'Sonja Haraldsen']\n",
      "        date: [[], [], [], [], [], [], [], [], []]\n",
      "        id: ['54024', '93102', '128193', '122388', '59710', '92600', '67479', '20773', '59655']\n",
      "    Empress Matilda: \n",
      "        spouses: ['King Henry', 'England', 'Germany', 'Holy Roman Emperor Henry V']\n",
      "        date: [[], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
      "        id: ['93936', '136915', '5479', '149116', '45782', '83945', '115000', '24754', '8287', '71897', '3549', '100761', '76648', '126945']\n",
      "    Ann Romney: \n",
      "        spouses: ['Brigham Young University', 'BYU', 'Mitt Romney']\n",
      "        date: [[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
      "        id: ['180302', '180275', '180295', '180270', '204148', '180272', '180293', '180265', '180279', '204131', '204140', '204155', '204138', '180262', '180300', '180269', '180281', '180278']\n",
      "    Ellen DeGeneres: \n",
      "        spouses: ['Portia de Rossi']\n",
      "        date: [[], [], [], [], [], [], [], [], []]\n",
      "        id: ['36216', '8020', '102972', '128929', '13074', '36215', '123007', '133370']\n",
      "    Jennifer Aniston: \n",
      "        spouses: ['Brad Pitt']\n",
      "        date: [[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
      "        id: ['14294', '14295', '122621', '134684', '121989', '110870', '82957']\n",
      "    Turner: \n",
      "        spouses: ['Elizabeth Swann', 'World']\n",
      "        date: [[], [], []]\n",
      "        id: ['185318']\n",
      "    April: \n",
      "        spouses: ['Paul McCartney', 'Beatles']\n",
      "        date: [[]]\n",
      "        id: ['149917']\n",
      "    Joan Crawford: \n",
      "        spouses: ['Crawford']\n",
      "        date: [[], [], [], []]\n",
      "        id: ['122550', '82151', '92957', '50440']\n",
      "    George VI: \n",
      "        spouses: ['Lyon', 'Lady Elizabeth Bowes', 'Elizabeth']\n",
      "        date: [[], [], [], [], [], []]\n",
      "        id: ['5910', '50142', '63873', '8554', '52828', '101696']\n",
      "    Elizabeth II: \n",
      "        spouses: ['Greece', 'Philip', 'Denmark', 'Prince', 'Wales', 'Duke', 'Charles', 'Edinburgh']\n",
      "        date: [[]]\n",
      "        id: ['24301']\n",
      "    Christie Brinkley: \n",
      "        spouses: ['Billy Joel', 'Brinkley']\n",
      "        date: [[], [], [], []]\n",
      "        id: ['202971', '202963', '202974', '202977']\n",
      "    Sharon Tate: \n",
      "        spouses: ['Sharon Marie Tate Polanski', 'Fearless Vampire Killers', 'Tate', 'August', 'Roman Polanski', 'January']\n",
      "        date: [[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
      "        id: ['34060', '122616', '56225', '34903', '84904', '106014', '92075', '62326', '50485', '30838', '109761', '145794', '29467', '27908', '111283']\n",
      "    Michelle Obama: \n",
      "        spouses: ['Michelle', 'Barack']\n",
      "        date: [(None, None, '1992'), (None, None, '1992'), (None, None, '1992')]\n",
      "        id: ['93454', '56474', '63241']\n",
      "    Katie Price: \n",
      "        spouses: ['Kieran Hayler', 'Alex Reid', 'Peter Andre']\n",
      "        date: [[], [], [], [], [], [], [], [], []]\n",
      "        id: ['39567', '104859', '19398', '38159', '65122', '50018', '4508', '90892', '93240']\n",
      "    Charles: \n",
      "        spouses: ['Bourbon', 'France', 'England', 'Henrietta Maria']\n",
      "        date: [[], [], [], [], [], [], [], [], []]\n",
      "        id: ['84162', '80448', '43793', '7073', '43114', '208490', '208487']\n",
      "    Faith Evans: \n",
      "        spouses: ['Christopher', 'Wallace', 'New York', 'August', 'Bad Boy']\n",
      "        date: [[], [], [], [], []]\n",
      "        id: ['126634', '130700', '102683', '44827', '107379']\n",
      "    Mel Brooks: \n",
      "        spouses: ['Oscar', 'Brooks', 'Anne Bancroft']\n",
      "        date: [[]]\n",
      "        id: ['97998']\n",
      "    Jacqueline Kennedy Onassis: \n",
      "        spouses: ['Aristotle Onassis']\n",
      "        date: [(None, None, '1968')]\n",
      "        id: ['4276']\n",
      "    Bruce Springsteen: \n",
      "        spouses: ['Patti Scialfa']\n",
      "        date: [[], [], [], [], [], []]\n",
      "        id: ['91266', '136247', '150581', '82667', '60871', '3364']\n",
      "    Triple H: \n",
      "        spouses: ['H']\n",
      "        date: [[], []]\n",
      "        id: ['185480']\n",
      "    Kris Jenner: \n",
      "        spouses: ['Kardashian', 'Caitlyn', 'Jenner', 'Robert', 'Olympic Games', 'Bruce Jenner', 'Robert Kardashian']\n",
      "        date: [[]]\n",
      "        id: ['135196']\n",
      "    Mamie Doud: \n",
      "        spouses: ['Mamie', 'West Point']\n",
      "        date: [[], [], []]\n",
      "        id: ['88306', '153695']\n",
      "    Elizabeth: \n",
      "        spouses: []\n",
      "        date: [[], []]\n",
      "        id: ['19758', '89046']\n",
      "    Grace Kelly: \n",
      "        spouses: ['Monaco', 'April', 'Prince Rainier III', 'Princess', 'November', 'Patricia Kelly']\n",
      "        date: [[], [], [], []]\n",
      "        id: ['94120', '122062', '49444']\n",
      "    None: \n",
      "        spouses: ['Ann Davies']\n",
      "        date: [[], [], []]\n",
      "        id: ['209662', '140833', '16799']\n",
      "    Franklin Roosevelt: \n",
      "        spouses: ['Eleanor Roosevelt']\n",
      "        date: [[], [], [], []]\n",
      "        id: ['151172', '69891', '2168', '70851']\n",
      "    Pamela Anderson: \n",
      "        spouses: ['Anderson', 'Pamela Anderson Lee', 'Pamela Lee', 'Tommy Lee']\n",
      "        date: [[]]\n",
      "        id: ['66831']\n",
      "    Margaret: \n",
      "        spouses: ['Navarre', 'King Henry III', 'Valois', 'Charles IX']\n",
      "        date: [[], [], [], []]\n",
      "        id: ['220330', '128032', '220340', '220333']\n",
      "    William Shakespeare: \n",
      "        spouses: ['Judith', 'Susanna', 'Hamnet', 'Anne Hathaway']\n",
      "        date: [[]]\n",
      "        id: ['216889']\n",
      "    Tom Brady: \n",
      "        spouses: ['Patriots', 'New England Patriots']\n",
      "        date: [[], [], []]\n",
      "        id: ['67834']\n",
      "    Wonder Woman: \n",
      "        spouses: ['South America', 'Diana Prince', 'Army']\n",
      "        date: [[], [], [], [], [], []]\n",
      "        id: ['92192', '38963']\n",
      "    Keturah: \n",
      "        spouses: ['Genesis', 'Abraham', 'Sarah', 'Book']\n",
      "        date: [[], [], []]\n",
      "        id: ['79530', '32998']\n",
      "    November: \n",
      "        spouses: ['Mamie Doud', 'West Point']\n",
      "        date: [[], []]\n",
      "        id: ['82144', '16586']\n",
      "    Lady Elizabeth Bowes: \n",
      "        spouses: ['Lyon', 'George VI', 'Elizabeth']\n",
      "        date: [[]]\n",
      "        id: ['140009']\n",
      "    Barbara Bush: \n",
      "        spouses: ['World War II', 'New York', 'Rye']\n",
      "        date: [(None, None, None), (None, None, None)]\n",
      "        id: ['163489', '163492']\n",
      "    Mitt Romney: \n",
      "        spouses: ['Ann Davies']\n",
      "        date: [[]]\n",
      "        id: ['209660']\n",
      "    Elton John: \n",
      "        spouses: ['John', 'Furnish', 'December', 'Wales', 'David Furnish', 'England']\n",
      "        date: [[]]\n",
      "        id: ['75462']\n",
      "    Cindy McCain: \n",
      "        spouses: ['United States Senator', 'Arizona', 'John McCain', 'May', 'Cindy Lou Hensley McCain']\n",
      "        date: [[], [], [], []]\n",
      "        id: ['228811', '141994', '33810', '100209']\n",
      "    Marilyn Monroe: \n",
      "        spouses: ['Monroe', 'Los Angeles']\n",
      "        date: [[]]\n",
      "        id: ['77750']\n",
      "    Andrew Jackson: \n",
      "        spouses: ['Rachel Donelson Robards']\n",
      "        date: [[]]\n",
      "        id: ['94031']\n",
      "    Kim Kardashian: \n",
      "        spouses: ['Kanye West']\n",
      "        date: [(None, None, '2014'), (None, None, '2014')]\n",
      "        id: ['15761', '125569']\n",
      "    Natalie Wood: \n",
      "        spouses: ['Robert Wagner']\n",
      "        date: [[]]\n",
      "        id: ['57015']\n",
      "    Aishwarya Rai: \n",
      "        spouses: ['Miss World', 'November', 'Rai', 'Aishwarya Rai Bachchan', 'Abhishek Bachchan']\n",
      "        date: [[], [], []]\n",
      "        id: ['64026', '153071', '35734']\n",
      "    Lisa Marie Presley: \n",
      "        spouses: ['Presley', 'Michael Jackson', 'Nicolas Cage', 'Michael Lockwood']\n",
      "        date: [[], [], [], []]\n",
      "        id: ['3099']\n",
      "    September: \n",
      "        spouses: ['Paul McCartney', 'Beatles']\n",
      "        date: [[]]\n",
      "        id: ['9087']\n",
      "    Bruce Willis: \n",
      "        spouses: ['Demi Moore']\n",
      "        date: [[]]\n",
      "        id: ['129188']\n",
      "    Brad Pitt: \n",
      "        spouses: ['Jennifer Aniston']\n",
      "        date: [[]]\n",
      "        id: ['17198']\n",
      "    Queen Victoria: \n",
      "        spouses: ['Europe']\n",
      "        date: [[]]\n",
      "        id: ['142919']\n",
      "    Edward VIII: \n",
      "        spouses: ['Wallis']\n",
      "        date: [[]]\n",
      "        id: ['93524']\n",
      "    Chris Pérez: \n",
      "        spouses: ['April', 'Selena']\n",
      "        date: [[], []]\n",
      "        id: ['189682']\n",
      "    Kristen Bell: \n",
      "        spouses: ['Dax Shepard']\n",
      "        date: [[]]\n",
      "        id: ['156136']\n",
      "    Felicity Jones: \n",
      "        spouses: ['Stephen', 'Infinity']\n",
      "        date: [[]]\n",
      "        id: ['172784']\n",
      "    United States Naval Academy: \n",
      "        spouses: ['Mamie Doud', 'West Point']\n",
      "        date: [[]]\n",
      "        id: ['128777']\n",
      "    Cleopatra: \n",
      "        spouses: ['Ptolemy XIV', 'Ptolemy XIII']\n",
      "        date: [[]]\n",
      "        id: ['35321']\n",
      "    David Beckham: \n",
      "        spouses: ['Victoria Beckham']\n",
      "        date: [[]]\n",
      "        id: ['60776']\n"
     ]
    }
   ],
   "source": [
    "pretty_print_dict(relational_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Save/Load relational graph\n",
    "\n",
    "if save_graph:\n",
    "    with open(f\"{graph}/relational_graph.json\", \"w\") as fp:\n",
    "        json.dump(relational_graph, fp, indent=4)\n",
    "\n",
    "if load_graph:\n",
    "    with open(f\"{graph}/relational_graph.json\", \"r\") as f:\n",
    "        relational_graph = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premiere.01': {'John Wick: Chapter 2': {'locations': ['Los Angeles'],\n",
       "   'date': [['30', 'January', '2017']],\n",
       "   'id': ['138117', '48551', '9366', '138368', '61964', '97247', '9367']},\n",
       "  'Brave': {'locations': [],\n",
       "   'date': [['10', 'June', '2012']],\n",
       "   'id': ['209148', '209129', '209162']},\n",
       "  'Penny Dreadful': {'locations': [],\n",
       "   'date': [['9', None, None], ['11', 'May', '2014']],\n",
       "   'id': ['113668',\n",
       "    '88185',\n",
       "    '145475',\n",
       "    '33511',\n",
       "    '135923',\n",
       "    '40973',\n",
       "    '136982',\n",
       "    '63647',\n",
       "    '53104',\n",
       "    '149528',\n",
       "    '147369']},\n",
       "  'Snooki & Jwoww': {'locations': [],\n",
       "   'date': [['22', 'October', '2013'],\n",
       "    ['5', 'November', '2014'],\n",
       "    ['8', 'January', '2013']],\n",
       "   'id': ['183071',\n",
       "    '183054',\n",
       "    '183052',\n",
       "    '183061',\n",
       "    '183044',\n",
       "    '183068',\n",
       "    '183064',\n",
       "    '183060']},\n",
       "  'Sons of Anarchy': {'locations': [],\n",
       "   'date': [['3', 'September', '2008'],\n",
       "    ['9', 'September', '2014'],\n",
       "    ['9', 'December', '2014']],\n",
       "   'id': ['57',\n",
       "    '13852',\n",
       "    '108672',\n",
       "    '73620',\n",
       "    '99584',\n",
       "    '51560',\n",
       "    '58',\n",
       "    '61340',\n",
       "    '116506',\n",
       "    '82239']},\n",
       "  'The Sopranos': {'locations': ['the United States'],\n",
       "   'date': [['10', 'January', '1999']],\n",
       "   'id': ['28225',\n",
       "    '24918',\n",
       "    '12462',\n",
       "    '139320',\n",
       "    '116467',\n",
       "    '70496',\n",
       "    '9562',\n",
       "    '96381',\n",
       "    '135676',\n",
       "    '7280',\n",
       "    '57859',\n",
       "    '136736',\n",
       "    '8314',\n",
       "    '134122',\n",
       "    '75675']},\n",
       "  'Thor: The Dark World': {'locations': ['London'],\n",
       "   'date': [['22', 'October', '2013']],\n",
       "   'id': ['32278', '82503', '133505']},\n",
       "  'The Ren & Stimpy Show': {'locations': [],\n",
       "   'date': [['11', None, '1991']],\n",
       "   'id': ['121004', '22668', '53149', '143038', '6828', '97476']},\n",
       "  'Winter Passing': {'locations': [],\n",
       "   'date': [[None, None, '2005']],\n",
       "   'id': ['214644', '214654', '214659', '214658']},\n",
       "  'Teen Wolf': {'locations': [],\n",
       "   'date': [[None, None, '2011'], ['15', 'November', '2016']],\n",
       "   'id': ['84340',\n",
       "    '30948',\n",
       "    '16867',\n",
       "    '152049',\n",
       "    '23449',\n",
       "    '1540',\n",
       "    '110049',\n",
       "    '34796',\n",
       "    '62643',\n",
       "    '142833']},\n",
       "  'Captain America: The Winter Soldier': {'locations': ['Los Angeles'],\n",
       "   'date': [['13', 'March', '2014']],\n",
       "   'id': ['217436',\n",
       "    '217445',\n",
       "    '217439',\n",
       "    '217438',\n",
       "    '217441',\n",
       "    '217447',\n",
       "    '217433']},\n",
       "  'The Belko Experiment': {'locations': [],\n",
       "   'date': [['10', None, '2016']],\n",
       "   'id': ['35193',\n",
       "    '131146',\n",
       "    '147434',\n",
       "    '37460',\n",
       "    '2094',\n",
       "    '133762',\n",
       "    '118826',\n",
       "    '35444',\n",
       "    '75912',\n",
       "    '56118',\n",
       "    '50953']},\n",
       "  'Fantastic Beasts and Where to Find Them': {'locations': ['New York City'],\n",
       "   'date': [['10', None, '2016']],\n",
       "   'id': ['58443',\n",
       "    '34332',\n",
       "    '32343',\n",
       "    '111488',\n",
       "    '32342',\n",
       "    '145482',\n",
       "    '75338',\n",
       "    '2814',\n",
       "    '38428',\n",
       "    '143197',\n",
       "    '73157',\n",
       "    '153997',\n",
       "    '113084',\n",
       "    '36946',\n",
       "    '86337',\n",
       "    '106356',\n",
       "    '100660',\n",
       "    '151390',\n",
       "    '3741',\n",
       "    '60155',\n",
       "    '29776',\n",
       "    '55524',\n",
       "    '109707',\n",
       "    '22369',\n",
       "    '66007']},\n",
       "  'A Monster Calls': {'locations': [],\n",
       "   'date': [['10', 'September', '2016']],\n",
       "   'id': ['122156', '125241', '97020', '131998', '118782']},\n",
       "  'Prison Break': {'locations': [],\n",
       "   'date': [['4', 'April', '2017']],\n",
       "   'id': ['64233',\n",
       "    '83960',\n",
       "    '121566',\n",
       "    '119476',\n",
       "    '81442',\n",
       "    '123630',\n",
       "    '143795',\n",
       "    '157857',\n",
       "    '150302',\n",
       "    '59999',\n",
       "    '109660',\n",
       "    '71369',\n",
       "    '70324',\n",
       "    '153266',\n",
       "    '144960',\n",
       "    '72534',\n",
       "    '26456',\n",
       "    '34948']},\n",
       "  'The Strain': {'locations': ['Texas', 'Austin'],\n",
       "   'date': [['13', 'July', '2014'],\n",
       "    ['12', 'July', '2015'],\n",
       "    ['28', 'August', '2016'],\n",
       "    ['16', 'July', '2017'],\n",
       "    [None, 'June', '2014']],\n",
       "   'id': ['82642',\n",
       "    '198200',\n",
       "    '63615',\n",
       "    '118187',\n",
       "    '183835',\n",
       "    '139049',\n",
       "    '183845',\n",
       "    '198194',\n",
       "    '107552',\n",
       "    '198198',\n",
       "    '183844',\n",
       "    '198203',\n",
       "    '198195',\n",
       "    '183851',\n",
       "    '183840']},\n",
       "  'Tropico': {'locations': [],\n",
       "   'date': [[None, 'December', '2013']],\n",
       "   'id': ['6328']},\n",
       "  'Rescue Me': {'locations': [],\n",
       "   'date': [['21', None, '2004']],\n",
       "   'id': ['166131',\n",
       "    '166128',\n",
       "    '166102',\n",
       "    '166126',\n",
       "    '166115',\n",
       "    '166108',\n",
       "    '166124',\n",
       "    '166109']},\n",
       "  'Lipstick Under My Burkha': {'locations': ['Tokyo'],\n",
       "   'date': [[]],\n",
       "   'id': ['146363', '96156', '73696', '46032', '34068', '122803']},\n",
       "  'The Promise': {'locations': [],\n",
       "   'date': [['11', 'September', '2016']],\n",
       "   'id': ['73489',\n",
       "    '506',\n",
       "    '29797',\n",
       "    '44071',\n",
       "    '95424',\n",
       "    '152759',\n",
       "    '122630',\n",
       "    '142023',\n",
       "    '29796',\n",
       "    '24746',\n",
       "    '74956']},\n",
       "  'Sleeping Beauty': {'locations': ['US'],\n",
       "   'date': [[None, None, None], ['2', None, '2011']],\n",
       "   'id': ['147944', '156382', '36530', '33490', '69977', '66204', '99616']},\n",
       "  'Mad Men': {'locations': [],\n",
       "   'date': [['19', 'July', '2007']],\n",
       "   'id': ['151807', '149499', '8978']},\n",
       "  'There Will Be Blood': {'locations': [],\n",
       "   'date': [[]],\n",
       "   'id': ['87259', '152464']},\n",
       "  'Avatar': {'locations': ['London'],\n",
       "   'date': [[None, None, '2009']],\n",
       "   'id': ['141791',\n",
       "    '104519',\n",
       "    '59621',\n",
       "    '115904',\n",
       "    '152457',\n",
       "    '90547',\n",
       "    '143669',\n",
       "    '81504']},\n",
       "  'The Vampire Diaries': {'locations': [],\n",
       "   'date': [['10', None, '2009']],\n",
       "   'id': ['39495',\n",
       "    '126593',\n",
       "    '11176',\n",
       "    '90481',\n",
       "    '78538',\n",
       "    '21162',\n",
       "    '11177',\n",
       "    '45684',\n",
       "    '125656',\n",
       "    '34107',\n",
       "    '174805',\n",
       "    '48998']},\n",
       "  'Cloud Atlas': {'locations': [],\n",
       "   'date': [['8', None, '2012']],\n",
       "   'id': ['216621',\n",
       "    '216633',\n",
       "    '216627',\n",
       "    '216646',\n",
       "    '216622',\n",
       "    '216647',\n",
       "    '216630',\n",
       "    '216631',\n",
       "    '216626']},\n",
       "  'Kong: Skull Island': {'locations': ['London'],\n",
       "   'date': [['28', 'February', '2017']],\n",
       "   'id': ['10282']},\n",
       "  'Rick and Morty': {'locations': [],\n",
       "   'date': [['26', 'July', '2015']],\n",
       "   'id': ['2395',\n",
       "    '45505',\n",
       "    '113031',\n",
       "    '53304',\n",
       "    '2396',\n",
       "    '119451',\n",
       "    '18977',\n",
       "    '8798']},\n",
       "  'Ink Master': {'locations': ['Spike'],\n",
       "   'date': [['17', 'January', '2012'],\n",
       "    ['23', 'June', '2015'],\n",
       "    ['23', None, '2016'],\n",
       "    ['23', None, None],\n",
       "    ['1', 'March', '2016']],\n",
       "   'id': ['87468',\n",
       "    '81581',\n",
       "    '6795',\n",
       "    '6796',\n",
       "    '51313',\n",
       "    '44746',\n",
       "    '1651',\n",
       "    '76366',\n",
       "    '10227']},\n",
       "  'Frenemies': {'locations': ['Canada', 'the United States'],\n",
       "   'date': [[], ['13', None, '2012']],\n",
       "   'id': ['177580',\n",
       "    '177565',\n",
       "    '177562',\n",
       "    '177577',\n",
       "    '177579',\n",
       "    '177578',\n",
       "    '177544',\n",
       "    '177584',\n",
       "    '177553']},\n",
       "  'Room': {'locations': [],\n",
       "   'date': [['4', None, '2015']],\n",
       "   'id': ['2569',\n",
       "    '2570',\n",
       "    '65428',\n",
       "    '45931',\n",
       "    '66629',\n",
       "    '15924',\n",
       "    '152585',\n",
       "    '23576']},\n",
       "  'Ballet Shoes': {'locations': [],\n",
       "   'date': [[]],\n",
       "   'id': ['205292',\n",
       "    '205298',\n",
       "    '205294',\n",
       "    '205299',\n",
       "    '205313',\n",
       "    '205323',\n",
       "    '205319']},\n",
       "  'New Girl': {'locations': [],\n",
       "   'date': [['20', 'September', '2011'], ['20', 'September', '2016']],\n",
       "   'id': ['188861',\n",
       "    '188837',\n",
       "    '110251',\n",
       "    '97833',\n",
       "    '157197',\n",
       "    '12595',\n",
       "    '188858',\n",
       "    '133263']},\n",
       "  \"Grey's Anatomy\": {'locations': [],\n",
       "   'date': [['27', 'March', '2005'], ['22', 'September', '2016']],\n",
       "   'id': ['72977',\n",
       "    '103880',\n",
       "    '140993',\n",
       "    '90853',\n",
       "    '101815',\n",
       "    '106340',\n",
       "    '3934',\n",
       "    '109404']},\n",
       "  'Horrible Bosses': {'locations': ['Los Angeles'],\n",
       "   'date': [['30', 'June', '2011']],\n",
       "   'id': ['166284', '166253']},\n",
       "  'The Breakfast Club': {'locations': ['Los Angeles'],\n",
       "   'date': [['7', 'February', '1985']],\n",
       "   'id': ['89855', '114646', '108412', '103411', '156948', '102275']},\n",
       "  'Broadchurch': {'locations': [],\n",
       "   'date': [['5', 'January', '2015'],\n",
       "    ['4', 'March', '2013'],\n",
       "    ['27', 'February', '2017']],\n",
       "   'id': ['149653', '128892', '41324', '14958', '105472', '116869']},\n",
       "  'Modern Family': {'locations': [],\n",
       "   'date': [['23', 'September', '2009'], ['21', 'September', '2016']],\n",
       "   'id': ['186960',\n",
       "    '77528',\n",
       "    '75907',\n",
       "    '186968',\n",
       "    '108832',\n",
       "    '78074',\n",
       "    '125475',\n",
       "    '94394',\n",
       "    '69092',\n",
       "    '96295',\n",
       "    '123423']},\n",
       "  'Wild': {'locations': [],\n",
       "   'date': [['29', 'August', '2014']],\n",
       "   'id': ['151765', '61474', '8293', '12393']},\n",
       "  'The Fate of the Furious': {'locations': ['Berlin'],\n",
       "   'date': [['4', None, '2017']],\n",
       "   'id': ['220892',\n",
       "    '220895',\n",
       "    '220906',\n",
       "    '220894',\n",
       "    '220907',\n",
       "    '220891',\n",
       "    '220887']},\n",
       "  'Zootopia': {'locations': ['Belgium'],\n",
       "   'date': [['13', 'February', '2016']],\n",
       "   'id': ['38710', '86561', '153943', '102265', '12107', '86320']},\n",
       "  'Spider-Man': {'locations': ['Philippines', 'Tokyo'],\n",
       "   'date': [['30', 'April', '2002'], ['16', None, '2007']],\n",
       "   'id': ['78132',\n",
       "    '225075',\n",
       "    '78965',\n",
       "    '146774',\n",
       "    '52001',\n",
       "    '18061',\n",
       "    '116601',\n",
       "    '53900',\n",
       "    '15927',\n",
       "    '103122',\n",
       "    '104933',\n",
       "    '58475']},\n",
       "  'Enemy': {'locations': [],\n",
       "   'date': [['8', 'September', '2013']],\n",
       "   'id': ['161583', '161586', '176871', '161563']},\n",
       "  'The Night Of': {'locations': [],\n",
       "   'date': [['10', None, '2016'], ['24', 'June', '2016']],\n",
       "   'id': ['97351', '77049', '9256', '9257', '222872', '139909']},\n",
       "  'Johnny Mnemonic': {'locations': [],\n",
       "   'date': [['15', 'April', '1995']],\n",
       "   'id': ['104028',\n",
       "    '128952',\n",
       "    '26988',\n",
       "    '31859',\n",
       "    '48531',\n",
       "    '149846',\n",
       "    '131917',\n",
       "    '8052',\n",
       "    '89466',\n",
       "    '3158']},\n",
       "  'Futurama': {'locations': [],\n",
       "   'date': [[None, None, '1999']],\n",
       "   'id': ['33396', '71258', '29646']},\n",
       "  'The Illusionist': {'locations': [],\n",
       "   'date': [[]],\n",
       "   'id': ['48932', '125718', '12694', '202390', '74309', '107728', '142158']},\n",
       "  'Fairy Tail': {'locations': ['Tokyo'],\n",
       "   'date': [[]],\n",
       "   'id': ['78819', '45676', '89357', '43745', '64530', '69372']},\n",
       "  'Black Sails': {'locations': [],\n",
       "   'date': [['24', 'January', '2015'], [], ['29', 'January', '2017']],\n",
       "   'id': ['173806', '219729', '219715']},\n",
       "  'In the Heart of the Sea': {'locations': ['New York City'],\n",
       "   'date': [['7', None, '2015']],\n",
       "   'id': ['71758',\n",
       "    '99823',\n",
       "    '26847',\n",
       "    '7069',\n",
       "    '124675',\n",
       "    '96623',\n",
       "    '107483',\n",
       "    '19208']},\n",
       "  'The Shield': {'locations': ['the United States'],\n",
       "   'date': [['12', 'March', '2002']],\n",
       "   'id': ['79690',\n",
       "    '120556',\n",
       "    '129773',\n",
       "    '115809',\n",
       "    '122731',\n",
       "    '67535',\n",
       "    '27872',\n",
       "    '91102']},\n",
       "  'The Messenger': {'locations': [],\n",
       "   'date': [[]],\n",
       "   'id': ['143914', '75936', '45524']},\n",
       "  'The Supernatural': {'locations': [],\n",
       "   'date': [['13', 'September', '2005']],\n",
       "   'id': ['19849', '135471', '95037', '155154', '148380', '19948']},\n",
       "  'The Suite Life Movie': {'locations': [],\n",
       "   'date': [['25', None, '2011']],\n",
       "   'id': ['91601']},\n",
       "  'Iron Man': {'locations': ['Sydney'],\n",
       "   'date': [['14', 'April', '2008']],\n",
       "   'id': ['22541', '3484']},\n",
       "  'Oz the Great and Powerful': {'locations': [],\n",
       "   'date': [['14', 'February', '2013']],\n",
       "   'id': ['193941',\n",
       "    '193925',\n",
       "    '193929',\n",
       "    '193959',\n",
       "    '193921',\n",
       "    '193965',\n",
       "    '193938',\n",
       "    '193930',\n",
       "    '193957',\n",
       "    '193924',\n",
       "    '193946',\n",
       "    '193931',\n",
       "    '193958']},\n",
       "  'Attack on Titan': {'locations': [],\n",
       "   'date': [[None, 'April', '2017']],\n",
       "   'id': ['45449', '31126', '31127', '111618', '21998', '12623', '118437']},\n",
       "  'X-Men: Days of Future Past': {'locations': ['New York City'],\n",
       "   'date': [['10', 'May', '2014']],\n",
       "   'id': ['115610', '2300']},\n",
       "  'Legion': {'locations': [],\n",
       "   'date': [['8', 'February', None]],\n",
       "   'id': ['229017',\n",
       "    '229038',\n",
       "    '176793',\n",
       "    '229031',\n",
       "    '229044',\n",
       "    '44873',\n",
       "    '229019',\n",
       "    '229030',\n",
       "    '229045',\n",
       "    '141902',\n",
       "    '229042',\n",
       "    '229028',\n",
       "    '229025',\n",
       "    '20674']},\n",
       "  'Beauty and the Beast': {'locations': ['London'],\n",
       "   'date': [['23', 'February', '2017']],\n",
       "   'id': ['81659', '17529', '22550']},\n",
       "  'Famous in Love': {'locations': [],\n",
       "   'date': [['18', 'April', '2017']],\n",
       "   'id': ['191605', '191598', '191622', '191600', '191592']},\n",
       "  'Trolls': {'locations': [],\n",
       "   'date': [['8', 'October', '2016']],\n",
       "   'id': ['75163', '209596', '209607']},\n",
       "  'The Great Buck Howard': {'locations': [],\n",
       "   'date': [['18', 'January', '2008']],\n",
       "   'id': ['152766']},\n",
       "  'Glee': {'locations': [],\n",
       "   'date': [['9', 'January', '2015'], ['19', 'May', '2009']],\n",
       "   'id': ['175833',\n",
       "    '8489',\n",
       "    '16778',\n",
       "    '175835',\n",
       "    '175828',\n",
       "    '175850',\n",
       "    '33851',\n",
       "    '175832',\n",
       "    '175849']},\n",
       "  'Elementary': {'locations': [],\n",
       "   'date': [['27', 'September', '2012'], []],\n",
       "   'id': ['212653', '212635', '212659', '68506']},\n",
       "  'The Avengers': {'locations': ['Hollywood'],\n",
       "   'date': [['11', 'April', '2012']],\n",
       "   'id': ['67316', '103995']},\n",
       "  \"Schindler's List\": {'locations': ['Washington', 'D.C.'],\n",
       "   'date': [['30', 'November', '1993']],\n",
       "   'id': ['121604', '57450', '17473', '65897', '51721']},\n",
       "  'The Carmichael Show': {'locations': [],\n",
       "   'date': [['26', 'August', '2015'], ['31', 'May', '2017']],\n",
       "   'id': ['221322', '221326', '221276', '221262', '221325']},\n",
       "  'The Leftovers': {'locations': [],\n",
       "   'date': [['29', 'June', '2014'],\n",
       "    ['4', 'October', '2015'],\n",
       "    ['16', 'April', '2017']],\n",
       "   'id': ['106677', '120444', '152674', '103788']},\n",
       "  'Short Term 12': {'locations': [],\n",
       "   'date': [['10', None, '2013']],\n",
       "   'id': ['201973', '202001', '201974']},\n",
       "  'Stephanie Daley': {'locations': [], 'date': [[]], 'id': ['90198', '88740']},\n",
       "  'BoJack Horseman': {'locations': ['Netflix'],\n",
       "   'date': [['22', 'August', '2014'], ['19', 'December', None]],\n",
       "   'id': ['90326', '23700', '23932', '41371', '8263']},\n",
       "  'True Detective': {'locations': [],\n",
       "   'date': [['12', 'January', '2014']],\n",
       "   'id': ['20419', '95113', '38833']},\n",
       "  'Doctor Who': {'locations': ['Canada', 'Alberta', 'Edmonton'],\n",
       "   'date': [['12', None, '1996'], ['15', None, '2017']],\n",
       "   'id': ['108729', '22198', '76267']},\n",
       "  'Ghostbusters': {'locations': ['Los Angeles'],\n",
       "   'date': [['9', None, '2016']],\n",
       "   'id': ['55257', '23667', '54990', '115596', '128384']},\n",
       "  'Whiplash': {'locations': [],\n",
       "   'date': [['16', 'January', '2014']],\n",
       "   'id': ['28147', '16936', '88818']},\n",
       "  'Interstellar': {'locations': ['Los Angeles'],\n",
       "   'date': [['26', None, '2014']],\n",
       "   'id': ['79685', '117012', '157951']},\n",
       "  'San Junipero': {'locations': ['Netflix'],\n",
       "   'date': [['21', 'October', '2016']],\n",
       "   'id': ['101053', '52683', '21540']},\n",
       "  'To the Bone': {'locations': [],\n",
       "   'date': [['22', 'January', '2017']],\n",
       "   'id': ['199149', '199147', '199145']},\n",
       "  'How to Be': {'locations': [],\n",
       "   'date': [['18', 'January', '2008']],\n",
       "   'id': ['221544']},\n",
       "  'Major Barbara': {'locations': [],\n",
       "   'date': [[None, None, '1905']],\n",
       "   'id': ['161073']},\n",
       "  \"Turn: Washington's Spies\": {'locations': [],\n",
       "   'date': [['13', 'April', '2015'], ['25', 'April', '2016']],\n",
       "   'id': ['220597', '220592']},\n",
       "  'American Horror Story': {'locations': [],\n",
       "   'date': [['7', 'October', '2015']],\n",
       "   'id': ['39305', '126598', '10744', '19328']},\n",
       "  'Her': {'locations': [],\n",
       "   'date': [['12', 'October', '2013']],\n",
       "   'id': ['142587', '85744']},\n",
       "  'Little Miss Sunshine': {'locations': [],\n",
       "   'date': [['20', 'January', '2006']],\n",
       "   'id': ['21556', '19507', '70461', '32603']},\n",
       "  'Fargo': {'locations': [],\n",
       "   'date': [['19', 'April', '2017']],\n",
       "   'id': ['8528', '74358']},\n",
       "  'Naruto': {'locations': [],\n",
       "   'date': [['10', 'September', '2005']],\n",
       "   'id': ['51407', '31064', '29350', '51406']},\n",
       "  'Line of Duty': {'locations': [],\n",
       "   'date': [['26', 'June', '2012']],\n",
       "   'id': ['41466', '68951', '6552', '101605', '17193', '55751']},\n",
       "  'Harry Potter': {'locations': ['Chicago'],\n",
       "   'date': [[None, None, '2009'], [None, 'November', '2016']],\n",
       "   'id': ['23313']},\n",
       "  'Interview': {'locations': [],\n",
       "   'date': [[None, None, '2007']],\n",
       "   'id': ['136444']},\n",
       "  'Cars Toons': {'locations': [], 'date': [[]], 'id': ['93277']},\n",
       "  \"Miss Peregrine's Home for Peculiar Children\": {'locations': ['Texas',\n",
       "    'Austin'],\n",
       "   'date': [['25', None, '2016']],\n",
       "   'id': ['218405', '116509', '218401']},\n",
       "  'Guardians of the Galaxy': {'locations': ['Hollywood'],\n",
       "   'date': [['21', 'July', '2014']],\n",
       "   'id': ['168658']},\n",
       "  'The Girl on the Train': {'locations': ['London'],\n",
       "   'date': [['20', None, '2016']],\n",
       "   'id': ['169413']},\n",
       "  'Goliyon Ki Raasleela Ram-Leela': {'locations': [],\n",
       "   'date': [[None, None, None]],\n",
       "   'id': ['207641']},\n",
       "  'Love & Friendship': {'locations': [],\n",
       "   'date': [[None, 'January', '2016']],\n",
       "   'id': ['190883']}},\n",
       " 'marry.01': {'Wyatt Earp': {'spouses': ['Earp', 'Urilla Sutherland Earp'],\n",
       "   'date': [[], [], [], [], [], [], [], []],\n",
       "   'id': ['30166',\n",
       "    '124003',\n",
       "    '19664',\n",
       "    '140605',\n",
       "    '39026',\n",
       "    '18407',\n",
       "    '140570',\n",
       "    '114675']},\n",
       "  'Paul McCartney': {'spouses': [],\n",
       "   'date': [[], [], [], [], [], [], [], []],\n",
       "   'id': ['52015',\n",
       "    '149441',\n",
       "    '7983',\n",
       "    '135818',\n",
       "    '21689',\n",
       "    '157227',\n",
       "    '47751',\n",
       "    '62218']},\n",
       "  'Linda McCartney': {'spouses': ['Paul McCartney',\n",
       "    'Linda Louise',\n",
       "    'April',\n",
       "    'Lady McCartney',\n",
       "    'Beatles',\n",
       "    'September'],\n",
       "   'date': [[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []],\n",
       "   'id': ['117931',\n",
       "    '212352',\n",
       "    '32317',\n",
       "    '139088',\n",
       "    '71073',\n",
       "    '9274',\n",
       "    '67951',\n",
       "    '78468',\n",
       "    '9275',\n",
       "    '87083',\n",
       "    '112671',\n",
       "    '212351']},\n",
       "  'Jennifer Garner': {'spouses': ['Garner', 'Scott Foley'],\n",
       "   'date': [[],\n",
       "    [],\n",
       "    [],\n",
       "    [],\n",
       "    [],\n",
       "    [],\n",
       "    [],\n",
       "    [],\n",
       "    [],\n",
       "    [],\n",
       "    [],\n",
       "    [],\n",
       "    [],\n",
       "    [],\n",
       "    [],\n",
       "    [],\n",
       "    []],\n",
       "   'id': ['229394',\n",
       "    '4974',\n",
       "    '71362',\n",
       "    '61558',\n",
       "    '229389',\n",
       "    '229391',\n",
       "    '229401',\n",
       "    '229396',\n",
       "    '229397',\n",
       "    '4975',\n",
       "    '133008',\n",
       "    '57188']},\n",
       "  'Ellen Pompeo': {'spouses': ['Pompeo', 'Chris Ivery'],\n",
       "   'date': [[], [], [], [], [], []],\n",
       "   'id': ['89086', '114846', '137940', '61666', '83319', '118335']},\n",
       "  'Harald V': {'spouses': ['Harald', 'Norway', 'Sonja Haraldsen'],\n",
       "   'date': [[], [], [], [], [], [], [], [], []],\n",
       "   'id': ['54024',\n",
       "    '93102',\n",
       "    '128193',\n",
       "    '122388',\n",
       "    '59710',\n",
       "    '92600',\n",
       "    '67479',\n",
       "    '20773',\n",
       "    '59655']},\n",
       "  'Empress Matilda': {'spouses': ['King Henry',\n",
       "    'England',\n",
       "    'Germany',\n",
       "    'Holy Roman Emperor Henry V'],\n",
       "   'date': [[], [], [], [], [], [], [], [], [], [], [], [], [], []],\n",
       "   'id': ['93936',\n",
       "    '136915',\n",
       "    '5479',\n",
       "    '149116',\n",
       "    '45782',\n",
       "    '83945',\n",
       "    '115000',\n",
       "    '24754',\n",
       "    '8287',\n",
       "    '71897',\n",
       "    '3549',\n",
       "    '100761',\n",
       "    '76648',\n",
       "    '126945']},\n",
       "  'Ann Romney': {'spouses': ['Brigham Young University', 'BYU', 'Mitt Romney'],\n",
       "   'date': [[],\n",
       "    [],\n",
       "    [],\n",
       "    [],\n",
       "    [],\n",
       "    [],\n",
       "    [],\n",
       "    [],\n",
       "    [],\n",
       "    [],\n",
       "    [],\n",
       "    [],\n",
       "    [],\n",
       "    [],\n",
       "    [],\n",
       "    [],\n",
       "    [],\n",
       "    [],\n",
       "    []],\n",
       "   'id': ['180302',\n",
       "    '180275',\n",
       "    '180295',\n",
       "    '180270',\n",
       "    '204148',\n",
       "    '180272',\n",
       "    '180293',\n",
       "    '180265',\n",
       "    '180279',\n",
       "    '204131',\n",
       "    '204140',\n",
       "    '204155',\n",
       "    '204138',\n",
       "    '180262',\n",
       "    '180300',\n",
       "    '180269',\n",
       "    '180281',\n",
       "    '180278']},\n",
       "  'Ellen DeGeneres': {'spouses': ['Portia de Rossi'],\n",
       "   'date': [[], [], [], [], [], [], [], [], []],\n",
       "   'id': ['36216',\n",
       "    '8020',\n",
       "    '102972',\n",
       "    '128929',\n",
       "    '13074',\n",
       "    '36215',\n",
       "    '123007',\n",
       "    '133370']},\n",
       "  'Jennifer Aniston': {'spouses': ['Brad Pitt'],\n",
       "   'date': [[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []],\n",
       "   'id': ['14294', '14295', '122621', '134684', '121989', '110870', '82957']},\n",
       "  'Turner': {'spouses': ['Elizabeth Swann', 'World'],\n",
       "   'date': [[], [], []],\n",
       "   'id': ['185318']},\n",
       "  'April': {'spouses': ['Paul McCartney', 'Beatles'],\n",
       "   'date': [[]],\n",
       "   'id': ['149917']},\n",
       "  'Joan Crawford': {'spouses': ['Crawford'],\n",
       "   'date': [[], [], [], []],\n",
       "   'id': ['122550', '82151', '92957', '50440']},\n",
       "  'George VI': {'spouses': ['Lyon', 'Lady Elizabeth Bowes', 'Elizabeth'],\n",
       "   'date': [[], [], [], [], [], []],\n",
       "   'id': ['5910', '50142', '63873', '8554', '52828', '101696']},\n",
       "  'Elizabeth II': {'spouses': ['Greece',\n",
       "    'Philip',\n",
       "    'Denmark',\n",
       "    'Prince',\n",
       "    'Wales',\n",
       "    'Duke',\n",
       "    'Charles',\n",
       "    'Edinburgh'],\n",
       "   'date': [[]],\n",
       "   'id': ['24301']},\n",
       "  'Christie Brinkley': {'spouses': ['Billy Joel', 'Brinkley'],\n",
       "   'date': [[], [], [], []],\n",
       "   'id': ['202971', '202963', '202974', '202977']},\n",
       "  'Sharon Tate': {'spouses': ['Sharon Marie Tate Polanski',\n",
       "    'Fearless Vampire Killers',\n",
       "    'Tate',\n",
       "    'August',\n",
       "    'Roman Polanski',\n",
       "    'January'],\n",
       "   'date': [[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []],\n",
       "   'id': ['34060',\n",
       "    '122616',\n",
       "    '56225',\n",
       "    '34903',\n",
       "    '84904',\n",
       "    '106014',\n",
       "    '92075',\n",
       "    '62326',\n",
       "    '50485',\n",
       "    '30838',\n",
       "    '109761',\n",
       "    '145794',\n",
       "    '29467',\n",
       "    '27908',\n",
       "    '111283']},\n",
       "  'Michelle Obama': {'spouses': ['Michelle', 'Barack'],\n",
       "   'date': [[None, None, '1992'], [None, None, '1992'], [None, None, '1992']],\n",
       "   'id': ['93454', '56474', '63241']},\n",
       "  'Katie Price': {'spouses': ['Kieran Hayler', 'Alex Reid', 'Peter Andre'],\n",
       "   'date': [[], [], [], [], [], [], [], [], []],\n",
       "   'id': ['39567',\n",
       "    '104859',\n",
       "    '19398',\n",
       "    '38159',\n",
       "    '65122',\n",
       "    '50018',\n",
       "    '4508',\n",
       "    '90892',\n",
       "    '93240']},\n",
       "  'Charles': {'spouses': ['Bourbon', 'France', 'England', 'Henrietta Maria'],\n",
       "   'date': [[], [], [], [], [], [], [], [], []],\n",
       "   'id': ['84162', '80448', '43793', '7073', '43114', '208490', '208487']},\n",
       "  'Faith Evans': {'spouses': ['Christopher',\n",
       "    'Wallace',\n",
       "    'New York',\n",
       "    'August',\n",
       "    'Bad Boy'],\n",
       "   'date': [[], [], [], [], []],\n",
       "   'id': ['126634', '130700', '102683', '44827', '107379']},\n",
       "  'Mel Brooks': {'spouses': ['Oscar', 'Brooks', 'Anne Bancroft'],\n",
       "   'date': [[]],\n",
       "   'id': ['97998']},\n",
       "  'Jacqueline Kennedy Onassis': {'spouses': ['Aristotle Onassis'],\n",
       "   'date': [[None, None, '1968']],\n",
       "   'id': ['4276']},\n",
       "  'Bruce Springsteen': {'spouses': ['Patti Scialfa'],\n",
       "   'date': [[], [], [], [], [], []],\n",
       "   'id': ['91266', '136247', '150581', '82667', '60871', '3364']},\n",
       "  'Triple H': {'spouses': ['H'], 'date': [[], []], 'id': ['185480']},\n",
       "  'Kris Jenner': {'spouses': ['Kardashian',\n",
       "    'Caitlyn',\n",
       "    'Jenner',\n",
       "    'Robert',\n",
       "    'Olympic Games',\n",
       "    'Bruce Jenner',\n",
       "    'Robert Kardashian'],\n",
       "   'date': [[]],\n",
       "   'id': ['135196']},\n",
       "  'Mamie Doud': {'spouses': ['Mamie', 'West Point'],\n",
       "   'date': [[], [], []],\n",
       "   'id': ['88306', '153695']},\n",
       "  'Elizabeth': {'spouses': [], 'date': [[], []], 'id': ['19758', '89046']},\n",
       "  'Grace Kelly': {'spouses': ['Monaco',\n",
       "    'April',\n",
       "    'Prince Rainier III',\n",
       "    'Princess',\n",
       "    'November',\n",
       "    'Patricia Kelly'],\n",
       "   'date': [[], [], [], []],\n",
       "   'id': ['94120', '122062', '49444']},\n",
       "  'null': {'spouses': ['Ann Davies'],\n",
       "   'date': [[], [], []],\n",
       "   'id': ['209662', '140833', '16799']},\n",
       "  'Franklin Roosevelt': {'spouses': ['Eleanor Roosevelt'],\n",
       "   'date': [[], [], [], []],\n",
       "   'id': ['151172', '69891', '2168', '70851']},\n",
       "  'Pamela Anderson': {'spouses': ['Anderson',\n",
       "    'Pamela Anderson Lee',\n",
       "    'Pamela Lee',\n",
       "    'Tommy Lee'],\n",
       "   'date': [[]],\n",
       "   'id': ['66831']},\n",
       "  'Margaret': {'spouses': ['Navarre',\n",
       "    'King Henry III',\n",
       "    'Valois',\n",
       "    'Charles IX'],\n",
       "   'date': [[], [], [], []],\n",
       "   'id': ['220330', '128032', '220340', '220333']},\n",
       "  'William Shakespeare': {'spouses': ['Judith',\n",
       "    'Susanna',\n",
       "    'Hamnet',\n",
       "    'Anne Hathaway'],\n",
       "   'date': [[]],\n",
       "   'id': ['216889']},\n",
       "  'Tom Brady': {'spouses': ['Patriots', 'New England Patriots'],\n",
       "   'date': [[], [], []],\n",
       "   'id': ['67834']},\n",
       "  'Wonder Woman': {'spouses': ['South America', 'Diana Prince', 'Army'],\n",
       "   'date': [[], [], [], [], [], []],\n",
       "   'id': ['92192', '38963']},\n",
       "  'Keturah': {'spouses': ['Genesis', 'Abraham', 'Sarah', 'Book'],\n",
       "   'date': [[], [], []],\n",
       "   'id': ['79530', '32998']},\n",
       "  'November': {'spouses': ['Mamie Doud', 'West Point'],\n",
       "   'date': [[], []],\n",
       "   'id': ['82144', '16586']},\n",
       "  'Lady Elizabeth Bowes': {'spouses': ['Lyon', 'George VI', 'Elizabeth'],\n",
       "   'date': [[]],\n",
       "   'id': ['140009']},\n",
       "  'Barbara Bush': {'spouses': ['World War II', 'New York', 'Rye'],\n",
       "   'date': [[None, None, None], [None, None, None]],\n",
       "   'id': ['163489', '163492']},\n",
       "  'Mitt Romney': {'spouses': ['Ann Davies'], 'date': [[]], 'id': ['209660']},\n",
       "  'Elton John': {'spouses': ['John',\n",
       "    'Furnish',\n",
       "    'December',\n",
       "    'Wales',\n",
       "    'David Furnish',\n",
       "    'England'],\n",
       "   'date': [[]],\n",
       "   'id': ['75462']},\n",
       "  'Cindy McCain': {'spouses': ['United States Senator',\n",
       "    'Arizona',\n",
       "    'John McCain',\n",
       "    'May',\n",
       "    'Cindy Lou Hensley McCain'],\n",
       "   'date': [[], [], [], []],\n",
       "   'id': ['228811', '141994', '33810', '100209']},\n",
       "  'Marilyn Monroe': {'spouses': ['Monroe', 'Los Angeles'],\n",
       "   'date': [[]],\n",
       "   'id': ['77750']},\n",
       "  'Andrew Jackson': {'spouses': ['Rachel Donelson Robards'],\n",
       "   'date': [[]],\n",
       "   'id': ['94031']},\n",
       "  'Kim Kardashian': {'spouses': ['Kanye West'],\n",
       "   'date': [[None, None, '2014'], [None, None, '2014']],\n",
       "   'id': ['15761', '125569']},\n",
       "  'Natalie Wood': {'spouses': ['Robert Wagner'],\n",
       "   'date': [[]],\n",
       "   'id': ['57015']},\n",
       "  'Aishwarya Rai': {'spouses': ['Miss World',\n",
       "    'November',\n",
       "    'Rai',\n",
       "    'Aishwarya Rai Bachchan',\n",
       "    'Abhishek Bachchan'],\n",
       "   'date': [[], [], []],\n",
       "   'id': ['64026', '153071', '35734']},\n",
       "  'Lisa Marie Presley': {'spouses': ['Presley',\n",
       "    'Michael Jackson',\n",
       "    'Nicolas Cage',\n",
       "    'Michael Lockwood'],\n",
       "   'date': [[], [], [], []],\n",
       "   'id': ['3099']},\n",
       "  'September': {'spouses': ['Paul McCartney', 'Beatles'],\n",
       "   'date': [[]],\n",
       "   'id': ['9087']},\n",
       "  'Bruce Willis': {'spouses': ['Demi Moore'], 'date': [[]], 'id': ['129188']},\n",
       "  'Brad Pitt': {'spouses': ['Jennifer Aniston'],\n",
       "   'date': [[]],\n",
       "   'id': ['17198']},\n",
       "  'Queen Victoria': {'spouses': ['Europe'], 'date': [[]], 'id': ['142919']},\n",
       "  'Edward VIII': {'spouses': ['Wallis'], 'date': [[]], 'id': ['93524']},\n",
       "  'Chris Pérez': {'spouses': ['April', 'Selena'],\n",
       "   'date': [[], []],\n",
       "   'id': ['189682']},\n",
       "  'Kristen Bell': {'spouses': ['Dax Shepard'], 'date': [[]], 'id': ['156136']},\n",
       "  'Felicity Jones': {'spouses': ['Stephen', 'Infinity'],\n",
       "   'date': [[]],\n",
       "   'id': ['172784']},\n",
       "  'United States Naval Academy': {'spouses': ['Mamie Doud', 'West Point'],\n",
       "   'date': [[]],\n",
       "   'id': ['128777']},\n",
       "  'Cleopatra': {'spouses': ['Ptolemy XIV', 'Ptolemy XIII'],\n",
       "   'date': [[]],\n",
       "   'id': ['35321']},\n",
       "  'David Beckham': {'spouses': ['Victoria Beckham'],\n",
       "   'date': [[]],\n",
       "   'id': ['60776']}}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relational_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Graph utils\n",
    "\n",
    "def get_sentences_by_id(dataset, id):\n",
    "  index = dataset['id'].index(str(id))\n",
    "  print(dataset[index]['premise'])\n",
    "  print(dataset[index]['hypothesis'])\n",
    "\n",
    "\n",
    "def format_date(dates):\n",
    "  select_date = None\n",
    "  for date in dates:\n",
    "    if not date: continue\n",
    "    if not date[2]: continue\n",
    "    if date[2]: select_date = date[2]\n",
    "    if date[1] and date[2]: select_date = date[1] + \", \" + date[2]\n",
    "    if date[0] and date[1] and date[2]:\n",
    "      select_date = date[1] + \" \" + date[0] + \", \" + date[2]\n",
    "      break\n",
    "  return select_date\n",
    "\n",
    "\n",
    "def get_all_locations(graph, frame):\n",
    "  ...\n",
    "  all_locations = set()\n",
    "  for key in graph[frame].keys():\n",
    "    for location in graph[frame][key]['locations']:\n",
    "      all_locations.add(location)\n",
    "  return list(all_locations)\n",
    "\n",
    "\n",
    "def get_all_dates(graph, frame):\n",
    "  ...\n",
    "  all_dates = set()\n",
    "  for key in graph[frame].keys():\n",
    "    date = format_date( graph[frame][key]['date'])\n",
    "    all_dates.add(date)\n",
    "  return list(all_dates)\n",
    "\n",
    "\n",
    "location_hierarchy = {\n",
    "   \"United States\": [\n",
    "      \"California\", \n",
    "      \"Texas\", \n",
    "      \"Illinois\", \n",
    "      \"District of Columbia\",\n",
    "      \"New York\",\n",
    "      \"New York City\",\n",
    "      \"Washington\",\n",
    "      \"D.C.\",\n",
    "      \"Chicago\",\n",
    "      \"Austin\",\n",
    "      \"Hollywood\",\n",
    "      \"Los Angeles\"\n",
    "    ],\n",
    "   \"the United States\": [\n",
    "      \"California\", \n",
    "      \"Texas\", \n",
    "      \"Illinois\", \n",
    "      \"District of Columbia\",\n",
    "      \"New York\",\n",
    "      \"New York City\",\n",
    "      \"Washington\",\n",
    "      \"D.C.\",\n",
    "      \"Chicago\",\n",
    "      \"Austin\",\n",
    "      \"Hollywood\",\n",
    "      \"Los Angeles\"\n",
    "    ],\n",
    "   \"US\": [\n",
    "      \"California\", \n",
    "      \"Texas\", \n",
    "      \"Illinois\", \n",
    "      \"District of Columbia\",\n",
    "      \"New York\",\n",
    "      \"New York City\",\n",
    "      \"Washington\",\n",
    "      \"D.C.\",\n",
    "      \"Chicago\",\n",
    "      \"Austin\",\n",
    "      \"Hollywood\",\n",
    "      \"Los Angeles\"\n",
    "    ],\n",
    "    \"California\": [\"Hollywood\", \"Los Angeles\"],\n",
    "    \"Texas\": [\"Austin\"],\n",
    "    \"Illinois\": [\"Chicago\"],\n",
    "    \"District of Columbia\": [\"Washington\", \"D.C.\"],\n",
    "    \"New York\": [\"New York City\"],\n",
    "    \"Canada\": [\"Alberta\", \"Edmonton\"],\n",
    "    \"Japan\": [\"Tokyo\"],\n",
    "    \"Australia\":  [\"Sydney\"],\n",
    "    \"Germany\": [\"Berlin\"],\n",
    "    \"Belgium\": [\"Belgium\"],\n",
    "    \"Philippines\": [\"Philippines\"],\n",
    "    \"United Kingdom\": [\"London\"]\n",
    "\n",
    "}\n",
    "\n",
    "def is_contained(location, container, location_hierarchy):\n",
    "  \n",
    "  if container in location_hierarchy:\n",
    "    if location in location_hierarchy[container]: \n",
    "      return True\n",
    "\n",
    "  return False\n",
    "\n",
    "def get_random_exclusive_element(main_list, exclusion_list):\n",
    "  exclusion_set = set(exclusion_list)\n",
    "  filtered_list = [item for item in main_list if item not in exclusion_set]\n",
    "  \n",
    "  if not filtered_list: return None  \n",
    "  choice = random.choice(filtered_list)\n",
    "  check = True\n",
    "  while check:\n",
    "    choice = random.choice(filtered_list)\n",
    "    for location in exclusion_list:\n",
    "      # print(\"choice \", choice)\n",
    "      # print(\"location \", location)\n",
    "      # print(\"is contained \", is_contained(choice, location, location_hierarchy))\n",
    "      # print(\"contains \", is_contained(location, choice, location_hierarchy))\n",
    "      # print()\n",
    "      related = is_contained(choice, location, location_hierarchy) or is_contained(location, choice, location_hierarchy) or choice == 'Netflix' or choice == 'Spike'\n",
    "      if not related: \n",
    "        check = False\n",
    "        break\n",
    "    \n",
    "  return choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(is_contained(\"the United States\", \"Tokyo\", location_hierarchy))  # True\n",
    "print(is_contained(\"Tokyo\", \"the United States\", location_hierarchy))  # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contraddictions\n",
      "John Wick: Chapter 2 premiered in New York City on January 30, 2022.\n",
      "Brave premiered on June 10, 2014.\n",
      "Penny Dreadful premiered on May 11, 2010.\n",
      "Snooki & Jwoww premiered on October 22, 2011.\n",
      "Sons of Anarchy premiered on September 3, 2004.\n",
      "The Sopranos premiered in Sydney on January 10, 1995.\n",
      "Thor: The Dark World premiered in the United States on October 22, 2017.\n",
      "The Ren & Stimpy Show premiered on 1996.\n",
      "Winter Passing premiered on 2008.\n",
      "Teen Wolf premiered on November 15, 2020.\n",
      "Captain America: The Winter Soldier premiered in Los Angeles on March 13, 2012.\n",
      "The Belko Experiment premiered on 2021.\n",
      "Fantastic Beasts and Where to Find Them premiered in Hollywood on 2016.\n",
      "A Monster Calls premiered on September 10, 2019.\n",
      "Prison Break premiered on April 4, 2012.\n",
      "The Strain premiered in Washington on July 13, 2011.\n",
      "Tropico premiered on December, 2012.\n",
      "Rescue Me premiered on 2003.\n",
      "Lipstick Under My Burkha premiered in D.C..\n",
      "The Promise premiered on September 11, 2019.\n",
      "Sleeping Beauty premiered in US on 2012.\n",
      "Mad Men premiered on July 19, 2006.\n",
      "Avatar premiered in Los Angeles on 2004.\n",
      "The Vampire Diaries premiered on 2004.\n",
      "Cloud Atlas premiered on 2015.\n",
      "Kong: Skull Island premiered in Hollywood on February 28, 2017.\n",
      "Rick and Morty premiered on July 26, 2019.\n",
      "Ink Master premiered in Berlin on January 17, 2012.\n",
      "Frenemies premiered in Texas on 2015.\n",
      "Room premiered on 2013.\n",
      "New Girl premiered on September 20, 2014.\n",
      "Grey's Anatomy premiered on March 27, 2002.\n",
      "Horrible Bosses premiered in Edmonton on June 30, 2014.\n",
      "The Breakfast Club premiered in Los Angeles on February 7, 1982.\n",
      "Broadchurch premiered on January 5, 2019.\n",
      "Modern Family premiered on September 23, 2004.\n",
      "Wild premiered on August 29, 2011.\n",
      "The Fate of the Furious premiered in Berlin on 2015.\n",
      "Zootopia premiered in Belgium on February 13, 2012.\n",
      "Spider-Man premiered in Chicago on April 30, 2002.\n",
      "Enemy premiered on September 8, 2010.\n",
      "The Night Of premiered on June 24, 2021.\n",
      "Johnny Mnemonic premiered on April 15, 1994.\n",
      "Futurama premiered on 2001.\n",
      "Fairy Tail premiered in London.\n",
      "Black Sails premiered on January 24, 2014.\n",
      "In the Heart of the Sea premiered in New York City on 2016.\n",
      "The Shield premiered in Belgium on March 12, 2000.\n",
      "The Supernatural premiered on September 13, 2010.\n",
      "The Suite Life Movie premiered on 2007.\n",
      "Iron Man premiered in the United States on April 14, 2010.\n",
      "Oz the Great and Powerful premiered on February 14, 2015.\n",
      "Attack on Titan premiered on April, 2021.\n",
      "X-Men: Days of Future Past premiered in Chicago on May 10, 2014.\n",
      "Beauty and the Beast premiered in Austin on February 23, 2017.\n",
      "Famous in Love premiered on April 18, 2016.\n",
      "Trolls premiered on October 8, 2019.\n",
      "The Great Buck Howard premiered on January 18, 2007.\n",
      "Glee premiered on January 9, 2012.\n",
      "Elementary premiered on September 27, 2008.\n",
      "The Avengers premiered in Hollywood on April 11, 2007.\n",
      "Schindler's List premiered in Texas on November 30, 1995.\n",
      "The Carmichael Show premiered on August 26, 2017.\n",
      "The Leftovers premiered on June 29, 2010.\n",
      "Short Term 12 premiered on 2018.\n",
      "BoJack Horseman premiered in Washington on August 22, 2014.\n",
      "True Detective premiered on January 12, 2016.\n",
      "Doctor Who premiered in the United States on 2020.\n",
      "Ghostbusters premiered in Sydney on 2016.\n",
      "Whiplash premiered on January 16, 2010.\n",
      "Interstellar premiered in Philippines on 2014.\n",
      "San Junipero premiered in Chicago on October 21, 2016.\n",
      "To the Bone premiered on January 22, 2020.\n",
      "How to Be premiered on January 18, 2003.\n",
      "Major Barbara premiered on 1909.\n",
      "Turn: Washington's Spies premiered on April 13, 2019.\n",
      "American Horror Story premiered on October 7, 2013.\n",
      "Her premiered on October 12, 2008.\n",
      "Little Miss Sunshine premiered on January 20, 2004.\n",
      "Fargo premiered on April 19, 2019.\n",
      "Naruto premiered on September 10, 2002.\n",
      "Line of Duty premiered on June 26, 2013.\n",
      "Harry Potter premiered in Berlin on November, 2013.\n",
      "Interview premiered on 2006.\n",
      "Miss Peregrine's Home for Peculiar Children premiered in Austin on 2020.\n",
      "Guardians of the Galaxy premiered in Sydney on July 21, 2017.\n",
      "The Girl on the Train premiered in Los Angeles on 2016.\n",
      "Love & Friendship premiered on January, 2019.\n",
      "neutrals\n",
      "L\n",
      "o\n",
      "v\n",
      "e\n",
      " \n",
      "&\n",
      " \n",
      "F\n",
      "r\n",
      "i\n",
      "e\n",
      "n\n",
      "d\n",
      "s\n",
      "h\n",
      "i\n",
      "p\n",
      "w\n",
      "a\n",
      "s\n",
      " \n",
      "a\n",
      "l\n",
      "s\n",
      "o\n",
      " \n",
      "r\n",
      "e\n",
      "l\n",
      "e\n",
      "a\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "a\n",
      "t\n",
      " \n",
      "L\n",
      "o\n",
      "n\n",
      "d\n",
      "o\n",
      "n\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "J\n",
      "a\n",
      "n\n",
      "u\n",
      "a\n",
      "r\n",
      "y\n",
      ",\n",
      " \n",
      "2\n",
      "0\n",
      "1\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "#@title Relational graph augmentation\n",
    "\n",
    "# dataset = filtered_dataset\n",
    "dataset = fever_dataset['train']\n",
    "new_hypotesys = []\n",
    "\n",
    "curr_id = max_id\n",
    "\n",
    "all_movie_locations = get_all_locations(relational_graph, \"premiere.01\")\n",
    "# print(f\"All movies locations: {all_movie_locations}\")\n",
    "all_movie_dates = get_all_dates(relational_graph, \"premiere.01\")\n",
    "# print(f\"All movies dates: {all_movie_dates}\")\n",
    "\n",
    "\n",
    "for frame in relational_graph.keys():\n",
    "\n",
    "  if frame == \"premiere.01\":\n",
    "\n",
    "    # synset = get_synset_from_id('1718331v')\n",
    "    contraddictions = []\n",
    "    neutrals = []\n",
    "\n",
    "    # go over all the titles in the graph\n",
    "    for title, infos in relational_graph[frame].items():\n",
    "      locations = relational_graph[frame][title]['locations']\n",
    "      dates =  relational_graph[frame][title]['date']\n",
    "      ids =  relational_graph[frame][title]['id']\n",
    "\n",
    "      if locations: select_location = locations[random.randint(0, len(locations)-1)]\n",
    "      # print(dates)\n",
    "      date = format_date(dates)\n",
    "      select_date = date\n",
    "\n",
    "      contraddiction = title + \" \"\n",
    "      if len(locations) >= 1 and date:\n",
    "        ... # choose randomly what to change\n",
    "        # print(title)\n",
    "\n",
    "        if random.randint(1, 100) <= 33: \n",
    "          # change date by randomly adding or subtracting 1 to 10 years\n",
    "          sign = 1 if random.randint(1, 100) <= 50 else -1\n",
    "          new_date = date[:-4] + str(int(date[-4:]) + (sign * random.randint(1, 5)))\n",
    "          # print(date)\n",
    "          # print(new_date)\n",
    "          select_date = new_date\n",
    "\n",
    "        elif 33 <= random.randint(1, 100) <= 66:\n",
    "          # change location\n",
    "          new_location = get_random_exclusive_element(all_movie_locations, locations)\n",
    "          # print(f\"curr locations: {locations}\")\n",
    "          # print(f\"new location = {new_location}\\n\")\n",
    "          select_location = new_location\n",
    "\n",
    "        else:\n",
    "          # change both\n",
    "          sign = 1 if random.randint(1, 100) <= 50 else -1\n",
    "          select_date = date[:-4] + str(int(date[-4:]) + (sign * random.randint(1, 5)))\n",
    "          select_location = get_random_exclusive_element(all_movie_locations, locations)\n",
    "\n",
    "        contraddiction += \"premiered in \" + select_location + \" on \" + select_date + \".\"\n",
    "\n",
    "\n",
    "      elif len(locations) >= 1 and not date:\n",
    "        ... # change only location\n",
    "        new_location = get_random_exclusive_element(all_movie_locations, locations)\n",
    "        contraddiction += \"premiered in \" + new_location + \".\"\n",
    "\n",
    "      elif len(locations) <= 1 and date:\n",
    "        ... # change only date\n",
    "        sign = 1 if random.randint(1, 100) <= 50 else -1\n",
    "        new_date = date[:-4] + str(int(date[-4:]) + (sign * random.randint(1, 5)))\n",
    "        contraddiction += \"premiered on \" + new_date + \".\"\n",
    "\n",
    "      else:\n",
    "        ... # nothing to do \n",
    "        continue\n",
    "\n",
    "      if contraddiction: contraddictions.append(contraddiction)\n",
    "\n",
    "      neutral = \"\"\n",
    "      sign = 1 if random.randint(1, 100) <= 50 else -1\n",
    "      new_date = None\n",
    "      if date: new_date = date[:-4] + str(int(date[-4:]) + random.randint(1, 2))\n",
    "      if not locations: locations = ['unk']\n",
    "\n",
    "      new_location = get_random_exclusive_element(all_movie_locations, locations)\n",
    "\n",
    "      if new_date and new_location:\n",
    "        neutral = title + \"was also released at \" + new_location + \" on \" + new_date\n",
    "      else:\n",
    "        neutral = title + \"was also released at \" + new_location\n",
    "\n",
    "      if neutral: neutrals.append(neutrals)\n",
    "\n",
    "print(\"contraddictions\")\n",
    "for sentence in contraddictions:\n",
    "  print(sentence)\n",
    "\n",
    "print(\"neutrals\")\n",
    "for sentence in neutrals:\n",
    "  print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/51086 [00:49<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star vs. the Forces of Evil is an American animated television series produced by Disney Television Animation . Nefcy became the second woman to create an animated series for Disney Television Animation ( the first being Sue Rose , who created Pepper Ann ) , and the first woman to create a Disney XD series . The second season premiered on July 11 , 2016 .\n",
      "59\n",
      "[{'index': 0, 'text': 'Star', 'pos': 'PROPN', 'lemma': 'Star', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 1, 'text': 'vs.', 'pos': 'ADP', 'lemma': 'vs.', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 2, 'text': 'the', 'pos': 'DET', 'lemma': 'the', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 3, 'text': 'Forces', 'pos': 'PROPN', 'lemma': 'Forces', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 4, 'text': 'of', 'pos': 'ADP', 'lemma': 'of', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 5, 'text': 'Evil', 'pos': 'PROPN', 'lemma': 'Evil', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 6, 'text': 'is', 'pos': 'AUX', 'lemma': 'be', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 7, 'text': 'an', 'pos': 'DET', 'lemma': 'an', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 8, 'text': 'American', 'pos': 'ADJ', 'lemma': 'american', 'bnSynsetId': 'bn:00096963a', 'wnSynsetOffset': '2927512a', 'nltkSynset': 'american.a.01'}, {'index': 9, 'text': 'animated', 'pos': 'VERB', 'lemma': 'animate', 'bnSynsetId': 'bn:00082628v', 'wnSynsetOffset': '547995v', 'nltkSynset': 'animize.v.01'}, {'index': 10, 'text': 'television', 'pos': 'NOUN', 'lemma': 'television', 'bnSynsetId': 'bn:00076373n', 'wnSynsetOffset': '6277280n', 'nltkSynset': 'television.n.01'}, {'index': 11, 'text': 'series', 'pos': 'NOUN', 'lemma': 'series', 'bnSynsetId': 'bn:00070597n', 'wnSynsetOffset': '6621447n', 'nltkSynset': 'serial.n.01'}, {'index': 12, 'text': 'produced', 'pos': 'VERB', 'lemma': 'produce', 'bnSynsetId': 'bn:00084094v', 'wnSynsetOffset': '2157100v', 'nltkSynset': 'produce.v.06'}, {'index': 13, 'text': 'by', 'pos': 'ADP', 'lemma': 'by', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 14, 'text': 'Disney', 'pos': 'PROPN', 'lemma': 'Disney', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 15, 'text': 'Television', 'pos': 'PROPN', 'lemma': 'Television', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 16, 'text': 'Animation', 'pos': 'PROPN', 'lemma': 'Animation', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 17, 'text': '.', 'pos': 'PUNCT', 'lemma': '.', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 18, 'text': 'Nefcy', 'pos': 'PROPN', 'lemma': 'Nefcy', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 19, 'text': 'became', 'pos': 'VERB', 'lemma': 'become', 'bnSynsetId': 'bn:00083294v', 'wnSynsetOffset': '2626604v', 'nltkSynset': 'become.v.02'}, {'index': 20, 'text': 'the', 'pos': 'DET', 'lemma': 'the', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 21, 'text': 'second', 'pos': 'ADJ', 'lemma': 'second', 'bnSynsetId': 'bn:00095974a', 'wnSynsetOffset': '2202146a', 'nltkSynset': 'second.s.01'}, {'index': 22, 'text': 'woman', 'pos': 'NOUN', 'lemma': 'woman', 'bnSynsetId': 'bn:00001530n', 'wnSynsetOffset': '10787470n', 'nltkSynset': 'woman.n.01'}, {'index': 23, 'text': 'to', 'pos': 'PART', 'lemma': 'to', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 24, 'text': 'create', 'pos': 'VERB', 'lemma': 'create', 'bnSynsetId': 'bn:00086009v', 'wnSynsetOffset': '1753788v', 'nltkSynset': 'create.v.02'}, {'index': 25, 'text': 'an', 'pos': 'DET', 'lemma': 'an', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 26, 'text': 'animated', 'pos': 'VERB', 'lemma': 'animate', 'bnSynsetId': 'bn:00082628v', 'wnSynsetOffset': '547995v', 'nltkSynset': 'animize.v.01'}, {'index': 27, 'text': 'series', 'pos': 'NOUN', 'lemma': 'series', 'bnSynsetId': 'bn:00070597n', 'wnSynsetOffset': '6621447n', 'nltkSynset': 'serial.n.01'}, {'index': 28, 'text': 'for', 'pos': 'ADP', 'lemma': 'for', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 29, 'text': 'Disney', 'pos': 'PROPN', 'lemma': 'Disney', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 30, 'text': 'Television', 'pos': 'PROPN', 'lemma': 'Television', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 31, 'text': 'Animation', 'pos': 'PROPN', 'lemma': 'Animation', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 32, 'text': '(', 'pos': 'PUNCT', 'lemma': '(', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 33, 'text': 'the', 'pos': 'DET', 'lemma': 'the', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 34, 'text': 'first', 'pos': 'ADJ', 'lemma': 'first', 'bnSynsetId': 'bn:00103006a', 'wnSynsetOffset': '1010862a', 'nltkSynset': 'first.a.01'}, {'index': 35, 'text': 'being', 'pos': 'AUX', 'lemma': 'be', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 36, 'text': 'Sue', 'pos': 'PROPN', 'lemma': 'Sue', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 37, 'text': 'Rose', 'pos': 'PROPN', 'lemma': 'Rose', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 38, 'text': ',', 'pos': 'PUNCT', 'lemma': ',', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 39, 'text': 'who', 'pos': 'PRON', 'lemma': 'who', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 40, 'text': 'created', 'pos': 'VERB', 'lemma': 'create', 'bnSynsetId': 'bn:00086009v', 'wnSynsetOffset': '1753788v', 'nltkSynset': 'create.v.02'}, {'index': 41, 'text': 'Pepper', 'pos': 'PROPN', 'lemma': 'Pepper', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 42, 'text': 'Ann', 'pos': 'PROPN', 'lemma': 'Ann', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 43, 'text': ')', 'pos': 'PUNCT', 'lemma': ')', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 44, 'text': ',', 'pos': 'PUNCT', 'lemma': ',', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 45, 'text': 'and', 'pos': 'CCONJ', 'lemma': 'and', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 46, 'text': 'the', 'pos': 'DET', 'lemma': 'the', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 47, 'text': 'first', 'pos': 'ADJ', 'lemma': 'first', 'bnSynsetId': 'bn:00103006a', 'wnSynsetOffset': '1010862a', 'nltkSynset': 'first.a.01'}, {'index': 48, 'text': 'woman', 'pos': 'NOUN', 'lemma': 'woman', 'bnSynsetId': 'bn:00001530n', 'wnSynsetOffset': '10787470n', 'nltkSynset': 'woman.n.01'}, {'index': 49, 'text': 'to', 'pos': 'PART', 'lemma': 'to', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 50, 'text': 'create', 'pos': 'VERB', 'lemma': 'create', 'bnSynsetId': 'bn:00086009v', 'wnSynsetOffset': '1753788v', 'nltkSynset': 'create.v.02'}, {'index': 51, 'text': 'a', 'pos': 'DET', 'lemma': 'a', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 52, 'text': 'Disney', 'pos': 'PROPN', 'lemma': 'Disney', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 53, 'text': 'XD', 'pos': 'PROPN', 'lemma': 'XD', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 54, 'text': 'series', 'pos': 'NOUN', 'lemma': 'series', 'bnSynsetId': 'bn:00070597n', 'wnSynsetOffset': '6621447n', 'nltkSynset': 'serial.n.01'}, {'index': 55, 'text': '.', 'pos': 'PUNCT', 'lemma': '.', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 56, 'text': 'The', 'pos': 'DET', 'lemma': 'the', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 57, 'text': 'second', 'pos': 'ADJ', 'lemma': 'second', 'bnSynsetId': 'bn:00095974a', 'wnSynsetOffset': '2202146a', 'nltkSynset': 'second.s.01'}, {'index': 58, 'text': 'season', 'pos': 'NOUN', 'lemma': 'season', 'bnSynsetId': 'bn:00070056n', 'wnSynsetOffset': '15239579n', 'nltkSynset': 'season.n.01'}, {'index': 59, 'text': 'premiered', 'pos': 'VERB', 'lemma': 'premiere', 'bnSynsetId': 'bn:00091964v', 'wnSynsetOffset': '1718331v', 'nltkSynset': 'premier.v.01'}, {'index': 60, 'text': 'on', 'pos': 'ADP', 'lemma': 'on', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 61, 'text': 'July', 'pos': 'PROPN', 'lemma': 'July', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 62, 'text': '11', 'pos': 'NUM', 'lemma': '11', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 63, 'text': ',', 'pos': 'PUNCT', 'lemma': ',', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 64, 'text': '2016', 'pos': 'NUM', 'lemma': '2016', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}, {'index': 65, 'text': '.', 'pos': 'PUNCT', 'lemma': '.', 'bnSynsetId': 'O', 'wnSynsetOffset': 'O', 'nltkSynset': 'O'}]\n",
      "{'index': 59, 'text': 'premiered', 'pos': 'VERB', 'lemma': 'premiere', 'bnSynsetId': 'bn:00091964v', 'wnSynsetOffset': '1718331v', 'nltkSynset': 'premier.v.01'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sample_range = len(fever_dataset['train'])\n",
    "loop = tqdm(range(sample_range))\n",
    "for i in range(sample_range):\n",
    "\n",
    "  data =  fever_dataset['train'][i]\n",
    "  sample_id = data['id']\n",
    "\n",
    "  premise = data['premise']\n",
    "  hypothesis = data['hypothesis']\n",
    "  label = data['label']\n",
    "  wsd = data['wsd']['premise']\n",
    "\n",
    "  if \"premiered on \" in premise:\n",
    "    print(premise)\n",
    "    index = premise.split(\" \").index(\"premiered\")\n",
    "    print(index)\n",
    "    print(wsd)\n",
    "    for val in wsd:\n",
    "      if val['index'] == index:\n",
    "        print(val)\n",
    "        \n",
    "    break\n",
    "\n",
    "\n",
    "\n",
    "  hypothesis = data['hypothesis']\n",
    "  new_hypotesys = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 308.51it/s]\n"
     ]
    }
   ],
   "source": [
    "#@title Augmentation by Synonyms and Hypernyms\n",
    "\n",
    "if syn_hyp_augment:\n",
    "  \n",
    "  sample_range = 10 #len(fever_dataset['train'])\n",
    "  loop = tqdm(range(sample_range))\n",
    "\n",
    "  new_samples = {\n",
    "      'id': [],\n",
    "      'premise': [],\n",
    "      'hypothesis': [],\n",
    "      'label': [],\n",
    "      'wsd': [None for i in range(sample_range)],\n",
    "      'srl': [None for i in range(sample_range)]\n",
    "  }\n",
    "\n",
    "  syn_dict = dict()\n",
    "  syn_idx = 0\n",
    "  progressive_id = int(max_id)\n",
    "\n",
    "  for i in loop:\n",
    "\n",
    "    data =  fever_dataset['train'][i]\n",
    "    sample_id = data['id']\n",
    "\n",
    "    premise = data['premise']\n",
    "    hypothesis = data['hypothesis']\n",
    "    label = data['label']\n",
    "    hyp_wsd = data['wsd']['hypothesis']\n",
    "\n",
    "    new_samples['id'].append(str(progressive_id))\n",
    "    new_samples['premise'].append(premise)\n",
    "    new_samples['label'].append(label)\n",
    "    progressive_id += 1\n",
    "\n",
    "    hypothesis = data['hypothesis']\n",
    "    new_hypotesys = []\n",
    "\n",
    "    for hyp_wsd_dict in hyp_wsd:\n",
    "\n",
    "      # substitute word with 50% probability\n",
    "      skip = False\n",
    "      if random.randint(1, 100) <= 50: \n",
    "        skip = True\n",
    "\n",
    "      word = hyp_wsd_dict['text']\n",
    "      pos = hyp_wsd_dict['pos']\n",
    "      offset = hyp_wsd_dict['wnSynsetOffset']\n",
    "      synset = get_synset_from_id(offset)\n",
    "\n",
    "      related_words = None\n",
    "      if synset: related_words = get_related_word(synset, pos)\n",
    "\n",
    "      if related_words and not skip:\n",
    "        hypernyms = related_words['hypernyms']\n",
    "        synonyms = related_words['synonyms']\n",
    "\n",
    "        chosen_subs = synonyms if random.randint(1, 100) <= 75 else hypernyms\n",
    "\n",
    "        if not chosen_subs : \n",
    "          new_hypotesys.append(word)\n",
    "          continue\n",
    "\n",
    "        synonym = chosen_subs[syn_idx % (len(chosen_subs))]\n",
    "\n",
    "        if synonym in syn_dict and syn_dict[synonym] > 10:\n",
    "          syn_idx += 1\n",
    "          synonym = chosen_subs[syn_idx % (len(chosen_subs))]\n",
    "\n",
    "        syn_dict[synonym] = 1 if  synonym not in syn_dict else syn_dict[synonym] + 1\n",
    "\n",
    "        syn_idx += 1\n",
    "\n",
    "        if '_' in synonym: synonym = synonym.replace('_', ' ')\n",
    "        new_hypotesys.append(synonym)\n",
    "\n",
    "      else: new_hypotesys.append(word)\n",
    "\n",
    "    if not new_hypotesys: \n",
    "      new_samples['hypothesis'].append(hypothesis)\n",
    "    else:\n",
    "      new_hypotesys = join_strings_smartly(new_hypotesys)\n",
    "      new_samples['hypothesis'].append(new_hypotesys)\n",
    "    # print(f\"new: {new_hypotesys} \\n\")\n",
    "\n",
    "  # print(new_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Roman Atwood is a content person.',\n",
       " 'The Boston Celtics play their home games at TD Garden.',\n",
       " 'There is a picture called The Hunger Games.',\n",
       " 'Ryan Seacrest is a person.',\n",
       " 'Stranger than Fiction is a film.',\n",
       " 'Selena recorded music.',\n",
       " 'Selena tape music.',\n",
       " 'Selena recorded music.',\n",
       " 'Selena recorded music.',\n",
       " 'John Wick: Chapter 2 was theatrically released in the Oregon.']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_samples['hypothesis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation type: <class 'datasets.arrow_dataset.Dataset'>\n",
      "Augmented dataset type: <class 'datasets.arrow_dataset.Dataset'>\n",
      "Train split length: 51086\n",
      "Train split augmentated: 51096\n"
     ]
    }
   ],
   "source": [
    "#@title Add new samples to the original dataset\n",
    " \n",
    "augmentation = Dataset.from_dict(new_samples)\n",
    "print(f\"Augmentation type: {type(augmentation)}\")\n",
    "\n",
    "augmented_dataset = concatenate_datasets([fever_dataset['train'], augmentation])\n",
    "print(f\"Augmented dataset type: {type(augmented_dataset)}\")\n",
    "print(f\"Train split length: {len(fever_dataset['train'])}\")\n",
    "print(f\"Train split augmentated: {len(augmented_dataset)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
